<h2 id="scientific-comprehension">1. AI for Scientific Comprehension</h2>


<h3 id="textual-scientific-comprehension">1.1 Textual Scientific Comprehension</h3>
<img src="./assets/images/scientific-comprehension.png" style="width: 580pt">
<h4 id="semi-automatic-scientific-comprehension">1.1.1 Semi-Automatic Scientific Comprehension</h4>
<b>Human-Guided Scientific Comprehension</b>
<ul>
<li><i><b>Clam: Selective clarification for ambiguous questions with generative language models</b></i>, Kuhn et al., <a href="https://arxiv.org/abs/2212.07769" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Clarify when necessary: Resolving ambiguity through interaction with lms</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2311.09469" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Empowering language models with active inquiry for deeper understanding</b></i>, Pang et al., <a href="https://arxiv.org/abs/2402.03719" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Iqa-eval: Automatic evaluation of human-model interactive question answering</b></i>, Li et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search</b></i>, Yamada et al., <a href="https://arxiv.org/abs/2504.08066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Truly Assessing Fluid Intelligence of Large Language Models through Dynamic Reasoning Evaluation</b></i>, Yang et al., <a href="https://arxiv.org/abs/2506.02648" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>Tool-Augmented Scientific Comprehension</b>
<ul>
<li><i><b>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding</b></i>, Wright et al., <img src="https://img.shields.io/badge/ACL Findings-2021-green" alt="ACL Findings Badge"></li>
<li><i><b>Scienceqa: A novel resource for question answering on scholarly articles</b></i>, Saikh et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Human and technological infrastructures of fact-checking</b></i>, Juneja et al., <img src="https://img.shields.io/badge/Other Source-2022.11-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Paperqa: Retrieval-augmented generative agent for scientific research</b></i>, Lala et al., <a href="https://arxiv.org/abs/2312.07559" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Efficacy analysis of online artificial intelligence fact-checking tools</b></i>, Hartley et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Language agents achieve superhuman synthesis of scientific knowledge</b></i>, Skarlinski et al., <a href="https://arxiv.org/abs/2409.13740" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a global perspective</b></i>, Yang et al., <a href="https://arxiv.org/abs/2410.17600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>SciAgent: Tool-augmented Language Models for Scientific Reasoning</b></i>, Ma et al., <a href="https://aclanthology.org/2024.emnlp-main.880/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>Hallucination Mitigation using Agentic AI Natural Language-Based Frameworks</b></i>, Gosmar et al., <a href="https://arxiv.org/abs/2501.13946" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation</b></i>, Kim et al., <a href="https://arxiv.org/abs/2502.03004" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards reasoning era: A survey of long chain-of-thought for reasoning large language models</b></i>, Chen et al., <a href="https://arxiv.org/abs/2503.09567" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering</b></i>, Chu et al., <a href="https://arxiv.org/abs/2505.19112" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2505.19108" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Self-guided Scientific Comprehension</b>
<ul>
<li><i><b>Boolq: Exploring the surprising difficulty of natural yes/no questions</b></i>, Clark et al., <a href="https://arxiv.org/abs/1905.10044" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.05-red" alt="arXiv Badge"></a></li>
<li><i><b>SciBERT: A Pretrained Language Model for Scientific Text</b></i>, Beltagy et al., <a href="https://aclanthology.org/D19-1371/" target="_blank"><img src="https://img.shields.io/badge/PDF-2019.11-blue" alt="PDF Badge"></a></li>
<li><i><b>CoQUAD: a COVID-19 question answering dataset system, facilitating research, benchmarking, and practice</b></i>, Raza et al., <img src="https://img.shields.io/badge/BMC bioinformatics-2022-green" alt="BMC bioinformatics Badge"></li>
<li><i><b>Quaser: Question answering with scalable extractive rationalization</b></i>, Ghoshal et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Spaceqa: Answering questions about the design of space missions and space craft concepts</b></i>, Garcia-Silva et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>What if: Generating code to answer simulation questions in chemistry texts</b></i>, Peretz et al., <img src="https://img.shields.io/badge/Other Source-2023.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Biomedlm: A 2.7 b parameter language model trained on biomedical text</b></i>, Bolton et al., <a href="https://arxiv.org/abs/2403.18421" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Scifibench: Benchmarking large multimodal models for scientific figure interpretation</b></i>, Roberts et al., <a href="https://arxiv.org/abs/2405.08807" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scholarchemqa: Unveiling the power of language models in chemical research question answering</b></i>, Chen et al., <a href="https://arxiv.org/abs/2407.16931" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Mmsci: A dataset for graduate-level multi-discipline multimodal scientific understanding</b></i>, Li et al., <a href="https://arxiv.org/abs/2407.04903" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models</b></i>, Li et al., <a href="https://aclanthology.org/2024.acl-long.775/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>What are the essential factors in crafting effective long context multi-hop instruction datasets? insights and best practices</b></i>, Chen et al., <a href="https://arxiv.org/abs/2409.01893" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study</b></i>, Rostam et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>L-CiteEval: Do Long-Context Models Truly Leverage Context for Responding?</b></i>, Tang et al., <a href="https://arxiv.org/abs/2410.02115" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Toward expert-level medical question answering with large language models</b></i>, Singhal et al., <img src="https://img.shields.io/badge/Nature Medicine-2025-green" alt="Nature Medicine Badge"></li>
<li><i><b>A comprehensive survey on long context language modeling</b></i>, Liu et al., <a href="https://arxiv.org/abs/2503.17407" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey on transformer context extension: Approaches and evaluation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2503.13299" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Scholarchemqa: Unveiling the power of language models in chemical research question answering</b></i>, Chen et al., <a href="https://arxiv.org/abs/2407.16931" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Evaluating and Training Long-Context Large Language Models for Question Answering on Scientific Papers</b></i>, Hilgert et al., <a href="https://aclanthology.org/2024.customnlp4u-1.17/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>Are plain language summaries more readable than scientific abstracts? Evidence from six biomedical and life sciences journals</b></i>, Wen et al., <img src="https://img.shields.io/badge/Public Understanding of Science-2025-green" alt="Public Understanding of Science Badge"></li>
</ul>

<h4 id="full-automatic-scientific-comprehension">1.1.2 Full-Automatic Scientific Comprehension</h4>
</ul>

<b>Summarization-guided Automatic Scientific Comprehension</b>
<ul>
<li><i><b>Straight from the scientist's mouth—plain language summaries promote laypeople's comprehension and knowledge acquisition when reading about individual research findings in psychology</b></i>, Kerwer et al., <img src="https://img.shields.io/badge/Collabra: Psychology-2021-green" alt="Collabra: Psychology Badge"></li>
<li><i><b>Hierarchical attention graph for scientific document summarization in global and local level</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2405.10202" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?</b></i>, Fonseca et al., <a href="https://aclanthology.org/2024.findings-acl.508/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research Papers</b></i>, Ifargan et al., <img src="https://img.shields.io/badge/NEJM AI-2025-green" alt="NEJM AI Badge"></li>
</ul>

<b>Self-Questioning & Self-Reflection Automatic Scientific Comprehension</b>
<ul>
<li><i><b>Large language models can self-improve</b></i>, Huang et al., <a href="https://arxiv.org/abs/2210.11610" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Selfcheck: Using llms to zero-shot check their own step-by-step reasoning</b></i>, Miao et al., <a href="https://arxiv.org/abs/2308.00436" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Enabling Language Models to Implicitly Learn Self-Improvement</b></i>, Wang et al., <a href="https://arxiv.org/abs/2310.00898" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciglm: Training scientific language models with self-reflective instruction annotation and tuning</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2401.07950" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Generating Multiple Choice Questions from Scientific Literature via Large Language Models</b></i>, Luo et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>SciQAG: A Framework for Auto-Generated Science Question Answering Dataset with Fine-grained Evaluation</b></i>, Wan et al., <a href="https://arxiv.org/abs/2405.09939" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Recursive introspection: Teaching language model agents how to self-improve</b></i>, Qu et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models</b></i>, Song et al., <a href="https://arxiv.org/abs/2412.02674" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights</b></i>, Yu et al., <a href="https://arxiv.org/abs/2505.04649" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment</b></i>, Wu et al., <a href="https://arxiv.org/abs/2505.12452" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>Open-retrieval conversational question answering</b></i>, Qu et al., <img src="https://img.shields.io/badge/Other Source-2020.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A non-factoid question-answering taxonomy</b></i>, Bolotova et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>How Well Do Large Language Models Extract Keywords? A Systematic Evaluation on Scientific Corpora</b></i>, Mansour et al., <a href="https://aclanthology.org/2025.aisd-main.2/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
</ul>



<h3 id="table-chart-scientific-comprehension">1.2 Table & Chart Scientific Comprehension</h3>
<h4 id="table-understanding">1.2.3 Table Understanding</h4>
</ul>

<ul>
<li><i><b>A survey on table-and-text hybridqa: Concepts, methods, challenges and future directions</b></i>, Wang et al., <a href="https://arxiv.org/abs/2212.13465" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding</b></i>, Wang et al., <a href="https://openreview.net/forum?id=4L0xnS4GQM" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.01-blue" alt="PDF Badge"></a></li>
<li><i><b>Improving demonstration diversity by human-free fusing for text-to-SQL</b></i>, Wang et al., <a href="https://arxiv.org/abs/2402.10663" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study</b></i>, Sui et al., <a href="https://doi.org/10.1145/3616855.3635752" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.03-blue" alt="PDF Badge"></a></li>
<li><i><b>Multimodal Table Understanding</b></i>, Zheng et al., <img src="https://img.shields.io/badge/ACL-2024-green" alt="ACL Badge"></li>
<li><i><b>Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding</b></i>, Ji et al., <a href="https://arxiv.org/abs/2411.08516" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Tablemaster: A recipe to advance table understanding with language models</b></i>, Cao et al., <a href="https://arxiv.org/abs/2501.19378" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of table reasoning with large language models</b></i>, Zhang et al., <img src="https://img.shields.io/badge/Frontiers of Computer Science-2025-green" alt="Frontiers of Computer Science Badge"></li>
<li><i><b>The Mighty ToRR: A Benchmark for Table Reasoning and Robustness</b></i>, Ashury-Tahan et al., <a href="https://arxiv.org/abs/2502.19412" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Tablebench: A comprehensive and complex benchmark for table question answering</b></i>, Wu et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
</ul>

<h4 id="chart-understanding">1.2.4 Chart Understanding</h4>
</ul>

<ul>
<li><i><b>Chartassisstant: A universal chart multimodal language model via chart-to-table pre-training and multitask instruction tuning</b></i>, Meng et al., <a href="https://arxiv.org/abs/2401.02384" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</b></i>, Pramanick et al., <a href="https://openreview.net/forum?id=h3lddsY5nf" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.07-blue" alt="PDF Badge"></a></li>
<li><i><b>ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning</b></i>, Masry et al., <a href="https://aclanthology.org/2024.findings-acl.619/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>ChartAssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning</b></i>, Meng et al., <a href="https://aclanthology.org/2024.findings-acl.463/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark</b></i>, Liang et al., <a href="https://aclanthology.org/2024.acl-short.11/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models</b></i>, Li et al., <a href="https://aclanthology.org/2024.acl-long.775/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>SynChart: Synthesizing Charts from Language Models</b></i>, Liu et al., <a href="https://arxiv.org/abs/2409.16517" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>NovaChart: A Large-scale Dataset towards Chart Understanding and Generation of Multimodal Large Language Models</b></i>, Hu et al., <a href="https://openreview.net/forum?id=PTYL6011vp" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.10-blue" alt="PDF Badge"></a></li>
<li><i><b>ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild</b></i>, Masry et al., <a href="https://aclanthology.org/2025.coling-industry.54/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.01-blue" alt="PDF Badge"></a></li>
<li><i><b>ChartSketcher: Reasoning with Multimodal Feedback and Reflection for Chart Understanding</b></i>, Huang et al., <a href="https://arxiv.org/abs/2505.19076" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework</b></i>, Yang et al., <a href="https://arxiv.org/abs/2506.02454" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>How well do large language models understand tables in materials science?</b></i>, Circi et al., <a href="https://link.springer.com/article/10.1007/s40192-024-00362-6" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.07-blue" alt="PDF Badge"></a></li>
<li><i><b>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models</b></i>, Newman et al., <a href="https://aclanthology.org/2024.emnlp-main.538/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>Sciverse: Unveiling the knowledge comprehension and visual reasoning of lmms on multi-modal scientific problems</b></i>, Guo et al., <a href="https://arxiv.org/abs/2503.10627" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
</ul>
<h2 id="academic-survey">2. AI for Academic Survey</h2>


<h3 id="related-work-retrieval">2.1 Related Work Retrieval</h3>
<img src="./assets/images/academic-survey.png" style="width: 580pt">
<b>Semantic-Guided Retrieval</b>
<ul>
<li><i><b>Scientific paper recommendation: A survey</b></i>, Bai et al., <img src="https://img.shields.io/badge/Ieee Access-2019-green" alt="Ieee Access Badge"></li>
<li><i><b>SPLADE v2: Sparse lexical and expansion model for information retrieval</b></i>, Formal et al., <a href="https://arxiv.org/abs/2109.10086" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Scientific paper recommendation systems: a literature review of recent publications</b></i>, Kreutz et al., <img src="https://img.shields.io/badge/Other Source-2022.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Clinical Trial Retrieval via Multi-grained Similarity Learning</b></i>, Luo et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Related Work and Citation Text Generation: A Survey</b></i>, Li et al., <a href="https://aclanthology.org/2024.emnlp-main.767/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>MIR: Methodology Inspiration Retrieval for Scientific Research Problems</b></i>, Garikaparthi et al., <a href="https://arxiv.org/abs/2506.00249" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>Graph-Guided Retrieval</b>
<ul>
<li><i><b>From who you know to what you read: Augmenting scientific recommendations with implicit social networks</b></i>, Kang et al., <img src="https://img.shields.io/badge/Other Source-2022.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Comlittee: Literature discovery with personal elected author committees</b></i>, Kang et al., <img src="https://img.shields.io/badge/Other Source-2023.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Citationsum: Citation-aware graph contrastive learning for scientific paper summarization</b></i>, Luo et al., <img src="https://img.shields.io/badge/Other Source-2023.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Explaining relationships among research papers</b></i>, Li et al., <a href="https://arxiv.org/abs/2402.13426" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction</b></i>, Boylan et al., <a href="https://arxiv.org/abs/2404.15923" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>An academic recommender system on large citation data based on clustering, graph modeling and deep learning</b></i>, Stergiopoulos et al., <img src="https://img.shields.io/badge/Knowledge and Information Systems-2024-green" alt="Knowledge and Information Systems Badge"></li>
<li><i><b>ArZiGo: A recommendation system for scientific articles</b></i>, Pinedo et al., <img src="https://img.shields.io/badge/Information Systems-2024-green" alt="Information Systems Badge"></li>
<li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a global perspective</b></i>, Yang et al., <a href="https://arxiv.org/abs/2410.17600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Taxonomy Tree Generation from Citation Graph</b></i>, Hu et al., <a href="https://arxiv.org/abs/2410.03761" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Construction and Application of Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model</b></i>, Ye et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Docs2KG: A Human-LLM Collaborative Approach to Unified Knowledge Graph Construction from Heterogeneous Documents</b></i>, Sun et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
</ul>

<b>LLM-Augmented Retrieval</b>
<ul>
<li><i><b>Paperweaver: Enriching topical paper alerts by contextualizing recommended papers with user-collected papers</b></i>, Lee et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source Question-Answer Systems using Large Language Models</b></i>, Seabra et al., <a href="https://arxiv.org/abs/2412.17964" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG</b></i>, Singh et al., <a href="https://arxiv.org/abs/2501.09136" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>CuriousLLM: Elevating multi-document question answering with llm-enhanced knowledge graph reasoning</b></i>, Yang et al., <img src="https://img.shields.io/badge/ACL-2025-green" alt="ACL Badge"></li>
<li><i><b>Introducing Deep Research</b></i>, {OpenAI} et al., <a href="https://openai.com/index/introducing-deep-research/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.02-blue" alt="PDF Badge"></a></li>
<li><i><b>LitLLMs, LLMs for Literature Review: Are we there yet?</b></i>, Agarwal et al., <a href="https://openreview.net/forum?id=heeJqQXKg7" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.04-blue" alt="PDF Badge"></a></li>
<li><i><b>Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.19647" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>GPT-4o Search Preview</b></i>, {OpenAI} et al., <a href="https://platform.openai.com/docs/models/gpt-4o-search-preview" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>WebDancer: Towards Autonomous Information Seeking Agency</b></i>, Wu et al., <a href="https://arxiv.org/abs/2505.22648" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Iterative self-incentivization empowers large language models as agentic searchers</b></i>, Shi et al., <a href="https://arxiv.org/abs/2505.20128" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework</b></i>, Yang et al., <a href="https://arxiv.org/abs/2506.02454" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents</b></i>, Du et al., <a href="https://arxiv.org/abs/2506.11763" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>AcademicBrowse: Benchmarking Academic Browse Ability of LLMs</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2506.13784" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Paper recommender systems: a literature survey</b></i>, Beel et al., <img src="https://img.shields.io/badge/Other Source-2016.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A Review on Personalized Academic Paper Recommendation.</b></i>, Li et al., <img src="https://img.shields.io/badge/Comput. Inf. Sci.-2019-green" alt="Comput. Inf. Sci. Badge"></li>
<li><i><b>Insights into relevant knowledge extraction techniques: a comprehensive review</b></i>, Shahid et al., <img src="https://img.shields.io/badge/The Journal of Supercomputing-2020-green" alt="The Journal of Supercomputing Badge"></li>
<li><i><b>A survey on rag meeting llms: Towards retrieval-augmented large language models</b></i>, Fan et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
</ul>



<h3 id="overview-report-generation">2.2 Overview Report Generation</h3>
<h4 id="research-roadmap-mapping">2.2.1 Research Roadmap Mapping</h4>
</ul>

<ul>
<li><i><b>Hierarchical catalogue generation for literature review: a benchmark</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2304.03512" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Assisting in writing wikipedia-like articles from scratch with large language models</b></i>, Shao et al., <a href="https://arxiv.org/abs/2402.14207" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Chime: Llm-assisted hierarchical organization of scientific studies for literature review support</b></i>, Hsu et al., <a href="https://arxiv.org/abs/2407.16148" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature</b></i>, Katz et al., <a href="https://arxiv.org/abs/2408.15836" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Understanding Survey Paper Taxonomy about Large Language Models via Graph Representation Learning</b></i>, Zhuang et al., <a href="https://aclanthology.org/2024.sdp-1.6/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Artificial intelligence for literature reviews: Opportunities and challenges</b></i>, Bolanos et al., <img src="https://img.shields.io/badge/Artificial Intelligence Review-2024-green" alt="Artificial Intelligence Review Badge"></li>
<li><i><b>Taxonomy Tree Generation from Citation Graph</b></i>, Hu et al., <a href="https://arxiv.org/abs/2410.03761" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMs for Literature Review: Are we there yet?</b></i>, Agarwal et al., <a href="https://arxiv.org/abs/2412.15249" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Autosurvey: Large language models can automatically write surveys</b></i>, Wang et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</b></i>, Yan et al., <a href="https://arxiv.org/abs/2503.04629" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards reasoning era: A survey of long chain-of-thought for reasoning large language models</b></i>, Chen et al., <a href="https://arxiv.org/abs/2503.09567" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Ai2 Scholar QA: Organized Literature Synthesis with Attribution</b></i>, Singh et al., <a href="https://arxiv.org/abs/2504.10861" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="section-level-related-work-generation">2.2.2 Section-level Related Work Generation</h4>
</ul>

<b>Extractive Related Work.</b>
<ul>
<li><i><b>Towards automated related work summarization</b></i>, Hoang et al., <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Automatic generation of related work sections in scientific papers: an optimization approach</b></i>, Hu et al., <img src="https://img.shields.io/badge/EMNLP-2014-green" alt="EMNLP Badge"></li>
<li><i><b>Neural related work summarization with a joint context-driven attention mechanism</b></i>, Wang et al., <a href="https://arxiv.org/abs/1901.09492" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Automatic generation of related work through summarizing citations</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2019.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Toc-rwg: Explore the combination of topic model and citation information for automatic related work generation</b></i>, Wang et al., <img src="https://img.shields.io/badge/Ieee Access-2019-green" alt="Ieee Access Badge"></li>
<li><i><b>Automatic Related Work Section Generation by Sentence Extraction and Reordering.</b></i>, Deng et al., <img src="https://img.shields.io/badge/Other Source-2021.01-lightgrey" alt="Other Source Badge"></li>
</ul>

<b>Generative Related Work.</b>
<ul>
<li><i><b>Neural related work summarization with a joint context-driven attention mechanism</b></i>, Wang et al., <a href="https://arxiv.org/abs/1901.09492" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated lay language summarization of biomedical scientific reviews</b></i>, Guo et al., <img src="https://img.shields.io/badge/AAAI-2021-green" alt="AAAI Badge"></li>
<li><i><b>BACO: A background knowledge-and content-based framework for citing sentence generation</b></i>, Ge et al., <img src="https://img.shields.io/badge/ACL-2021-green" alt="ACL Badge"></li>
<li><i><b>Capturing relations between scientific papers: An abstractive model for related work section generation</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2021.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Target-aware abstractive related work generation with contrastive learning</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Multi-document scientific summarization from a knowledge graph-centric view</b></i>, Wang et al., <a href="https://arxiv.org/abs/2209.04319" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Controllable citation sentence generation with language models</b></i>, Gu et al., <a href="https://arxiv.org/abs/2211.07066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Causal intervention for abstractive related work generation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2305.13685" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Cited text spans for citation text generation</b></i>, Li et al., <a href="https://arxiv.org/abs/2309.06365" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards a unified framework for reference retrieval and related work generation</b></i>, Shi et al., <img src="https://img.shields.io/badge/EMNLP Findings-2023-green" alt="EMNLP Findings Badge"></li>
<li><i><b>Explaining relationships among research papers</b></i>, Li et al., <a href="https://arxiv.org/abs/2402.13426" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Shallow synthesis of knowledge in gpt-generated texts: A case study in automatic related work composition</b></i>, Martin-Boyle et al., <a href="https://arxiv.org/abs/2402.12255" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Related work and citation text generation: A survey</b></i>, Li et al., <a href="https://arxiv.org/abs/2404.11588" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization</b></i>, Pu et al., <img src="https://img.shields.io/badge/NAACL-2024-green" alt="NAACL Badge"></li>
<li><i><b>Reinforced Subject-Aware Graph Neural Network for Related Work Generation</b></i>, Yu et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Disentangling Instructive Information from Ranked Multiple Candidates for Multi-Document Scientific Summarization</b></i>, Wang et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Toward Related Work Generation with Structure and Novelty Statement</b></i>, Nishimura et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization</b></i>, Pratapa et al., <a href="https://arxiv.org/abs/2504.12972" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization</b></i>, Achkar et al., <a href="https://arxiv.org/abs/2505.16349" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Towards automated related work summarization</b></i>, Hoang et al., <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Capturing relations between scientific papers: An abstractive model for related work section generation</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2021.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Target-aware abstractive related work generation with contrastive learning</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study</b></i>, Ovelman et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Related Work and Citation Text Generation: A Survey</b></i>, Li et al., <a href="https://aclanthology.org/2024.emnlp-main.767/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>376 Using a large language model to create lay summaries of clinical study descriptions</b></i>, Kaiser et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.19647" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="document-level-survey-generation">2.2.3 Document-level Survey Generation</h4>
</ul>

<ul>
<li><i><b>Analyzing the past to prepare for the future: Writing a literature review</b></i>, Webster et al., <img src="https://img.shields.io/badge/MIS quarterly-2002-green" alt="MIS quarterly Badge"></li>
<li><i><b>Hierarchical catalogue generation for literature review: a benchmark</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2304.03512" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Bio-sieve: exploring instruction tuning large language models for systematic review automation</b></i>, Robinson et al., <a href="https://arxiv.org/abs/2308.06610" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Litllm: A toolkit for scientific literature review</b></i>, Agarwal et al., <a href="https://arxiv.org/abs/2402.01788" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Assisting in writing wikipedia-like articles from scratch with large language models</b></i>, Shao et al., <a href="https://arxiv.org/abs/2402.14207" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence for literature reviews: Opportunities and challenges</b></i>, Bolanos et al., <img src="https://img.shields.io/badge/Artificial Intelligence Review-2024-green" alt="Artificial Intelligence Review Badge"></li>
<li><i><b>Language agents achieve superhuman synthesis of scientific knowledge</b></i>, Skarlinski et al., <a href="https://arxiv.org/abs/2409.13740" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Instruct Large Language Models to Generate Scientific Literature Survey Step by Step</b></i>, Lai et al., <img src="https://img.shields.io/badge/NLPCC-2024-green" alt="NLPCC Badge"></li>
<li><i><b>Openscholar: Synthesizing scientific literature with retrieval-augmented lms</b></i>, Asai et al., <a href="https://arxiv.org/abs/2411.14199" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Intelligent summaries: Will Artificial Intelligence mark the finale for biomedical literature reviews?</b></i>, Galli et al., <img src="https://img.shields.io/badge/Learned Publishing-2024-green" alt="Learned Publishing Badge"></li>
<li><i><b>Autosurvey: Large language models can automatically write surveys</b></i>, Wang et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>LAG: LLM agents for Leaderboard Auto Generation on Demanding</b></i>, Wu et al., <a href="https://arxiv.org/abs/2502.18209" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>SurveyX: Academic Survey Automation via Large Language Models</b></i>, Liang et al., <a href="https://arxiv.org/abs/2502.14776" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Automating research synthesis with domain-specific large language model fine-tuning</b></i>, Susnjak et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</b></i>, Yan et al., <a href="https://arxiv.org/abs/2503.04629" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>Towards automated related work summarization</b></i>, Hoang et al., <img src="https://img.shields.io/badge/Other Source-2010.08-lightgrey" alt="Other Source Badge"></li>
</ul>

</ul>

<ul>
<li><i><b>Pre-writing: The stage of discovery in the writing process</b></i>, Rohman et al., <img src="https://img.shields.io/badge/College Composition & Communication-1965-green" alt="College Composition & Communication Badge"></li>
</ul>

<h2 id="scientific-discovery">3. AI for Scientific Discovery</h2>


<h3 id="idea-mining">3.1 Idea Mining</h3>
<img src="./assets/images/scientific-discovery.png" style="width: 580pt">
<h4 id="idea-mining-from-internal-knowledge">3.1.1 Idea Mining from Internal Knowledge</h4>
<ul>
<li><i><b>Ideas are dimes a dozen: Large language models for idea generation in innovation</b></i>, Girotra et al., <img src="https://img.shields.io/badge/Other Source-2023.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Prompting Diverse Ideas: Increasing AI Idea Variance</b></i>, Meincke et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Using Large Language Models for Idea Generation in Innovation</b></i>, Meincke et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers</b></i>, Si et al., <a href="https://arxiv.org/abs/2409.04109" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Can Large Language Models Unlock Novel Scientific Research Ideas?</b></i>, Kumar et al., <a href="https://arxiv.org/abs/2409.06185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model</b></i>, Chen et al., <a href="https://arxiv.org/abs/2502.03325" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations</b></i>, Chen et al., <a href="https://arxiv.org/abs/2503.18865" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.21396" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhance Innovation by Boosting Idea Generation with Large Language Models</b></i>, Haarmann et al., <img src="https://img.shields.io/badge/INFORMS Journal on Computing-2025-green" alt="INFORMS Journal on Computing Badge"></li>
</ul>

<h4 id="idea-mining-from-external-signal">3.1.2 Idea Mining from External Signal</h4>
</ul>

<b>Idea Mining from External Knowledge</b>
<ul>
<li><i><b>Literature based discovery: models, methods, and trends</b></i>, Henry et al., <img src="https://img.shields.io/badge/Journal of biomedical informatics-2017-green" alt="Journal of biomedical informatics Badge"></li>
<li><i><b>Predicting the Future of AI with AI: High-quality link prediction in an exponentially growing knowledge network</b></i>, Krenn et al., <a href="https://arxiv.org/abs/2210.00881" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.10-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of large language models</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2303.18223" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models meet nlp: A survey</b></i>, Qin et al., <a href="https://arxiv.org/abs/2405.12819" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Position: data-driven discovery with large generative models</b></i>, Majumder et al., <img src="https://img.shields.io/badge/ICML-2024-green" alt="ICML Badge"></li>
<li><i><b>Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models</b></i>, Gu et al., <a href="https://arxiv.org/abs/2405.17044" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Interesting scientific idea generation using knowledge graphs and llms: Evaluations with 100 research group leaders</b></i>, Gu et al., <a href="https://arxiv.org/abs/2405.17044" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scimon: Scientific inspiration machines optimized for novelty</b></i>, Wang et al., <img src="https://img.shields.io/badge/ACL-2024-green" alt="ACL Badge"></li>
<li><i><b>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning</b></i>, Buehler et al., <img src="https://img.shields.io/badge/Other Source-2024.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Literature meets data: A synergistic approach to hypothesis generation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2410.17309" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Chain of ideas: Revolutionizing research via novel idea development with llm agents</b></i>, Li et al., <a href="https://arxiv.org/abs/2410.13185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>SciPIP: An LLM-based Scientific Paper Idea Proposer</b></i>, Wang et al., <a href="https://arxiv.org/abs/2410.23166" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research</b></i>, Gu et al., <a href="https://arxiv.org/abs/2412.14141" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Learning to Generate Research Idea with Dynamic Control</b></i>, Li et al., <a href="https://arxiv.org/abs/2412.14626" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Graph of AI Ideas: Leveraging Knowledge Graphs and LLMs for AI Research Idea Generation</b></i>, Gao et al., <a href="https://arxiv.org/abs/2503.08549" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Sparks of science: Hypothesis generation using structured paper data</b></i>, O'Neill et al., <a href="https://arxiv.org/abs/2504.12976" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<b>Idea Mining from External Environment Feedback</b>
<ul>
<li><i><b>gpt-researcher</b></i>, Assafelovic et al., <a href="https://github.com/assafelovic/gpt-researcher" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.05-blue" alt="PDF Badge"></a></li>
<li><i><b>Mlagentbench: Evaluating language agents on machine learning experimentation</b></i>, Huang et al., <a href="https://arxiv.org/abs/2310.03302" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Researchagent: Iterative research idea generation over scientific literature with large language models</b></i>, Baek et al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation</b></i>, Swanson et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling Discovery of New Ionizable Lipid Designs for mRNA Delivery</b></i>, Cui et al., <img src="https://img.shields.io/badge/BioRxiv-2025-green" alt="BioRxiv Badge"></li>
<li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a href="https://arxiv.org/abs/2502.18864" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Zochi Technical Report</b></i>, AI et al., <a href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Carl Technical Report</b></i>, Institute et al., <a href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>Ideasynth: Iterative research idea development through evolving and composing idea facets with literature-grounded feedback</b></i>, Pu et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
</ul>

<h4 id="idea-mining-from-team-discussion">3.1.3 Idea Mining from Team discussion</h4>
</ul>

<b>AI-AI Collaboration</b>
<ul>
<li><i><b>Large language models for automated open-domain scientific hypotheses discovery</b></i>, Yang et al., <a href="https://arxiv.org/abs/2309.02726" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Exploring collaboration mechanisms for llm agents: A social psychology view</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2310.02124" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Acceleron: A tool to accelerate research ideation</b></i>, Nigam et al., <a href="https://arxiv.org/abs/2403.04382" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Hypothesis generation with large language models</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2404.04326" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Researchagent: Iterative research idea generation over scientific literature with large language models</b></i>, Baek et al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery</b></i>, Ma et al., <a href="https://arxiv.org/abs/2405.09783" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning</b></i>, Ghafarollahi et al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation</b></i>, Su et al., <a href="https://arxiv.org/abs/2410.09403" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Chain of ideas: Revolutionizing research via novel idea development with llm agents</b></i>, Li et al., <a href="https://arxiv.org/abs/2410.13185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Nova: An iterative planning and search approach to enhance novelty and diversity of llm generated ideas</b></i>, Hu et al., <a href="https://arxiv.org/abs/2410.14255" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation</b></i>, Swanson et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>AIGS: Generating Science from AI-Powered Automated Falsification</b></i>, Liu et al., <a href="https://arxiv.org/abs/2411.11910" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses</b></i>, Yang et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback</b></i>, Yuan et al., <a href="https://arxiv.org/abs/2501.03916" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Multi-Novelty: Improve the Diversity and Novelty of Contents Generated by Large Language Models via inference-time Multi-Views Brainstorming</b></i>, Lagzian et al., <a href="https://arxiv.org/abs/2502.12700" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation</b></i>, Sinha et al., <a href="https://arxiv.org/abs/2502.19414" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration</b></i>, Pu et al., <a href="https://arxiv.org/abs/2505.15047" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Human-AI Collaboration</b>
<ul>
<li><i><b>An Interactive Co-Pilot for Accelerated Research Ideation</b></i>, Nigam et al., <a href="https://aclanthology.org/2024.hcinlp-1.6/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.06-blue" alt="PDF Badge"></a></li>
<li><i><b>Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination</b></i>, Radensky et al., <a href="https://arxiv.org/abs/2409.14634" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery</b></i>, Garikaparthi et al., <a href="https://arxiv.org/abs/2504.16728" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Human creativity in the age of llms: Randomized experiments on divergent and convergent thinking</b></i>, Kumar et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
</ul>

</ul>

<ul>
<li><i><b>Can Large Language Models Unlock Novel Scientific Research Ideas?</b></i>, Kumar et al., <a href="https://arxiv.org/abs/2409.06185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers</b></i>, Si et al., <a href="https://arxiv.org/abs/2409.04109" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research</b></i>, Gu et al., <a href="https://arxiv.org/abs/2412.14141" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models for causal hypothesis generation in science</b></i>, Cohrs et al., <img src="https://img.shields.io/badge/Other Source-2025.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Futuregen: Llm-rag approach to generate the future work of scientific article</b></i>, Azher et al., <a href="https://arxiv.org/abs/2503.16561" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition</b></i>, Liu et al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Sparks of science: Hypothesis generation using structured paper data</b></i>, O'Neill et al., <a href="https://arxiv.org/abs/2504.12976" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Spark: A System for Scientifically Creative Idea Generation</b></i>, Sanyal et al., <a href="https://arxiv.org/abs/2504.20090" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature</b></i>, Sternlicht et al., <a href="https://arxiv.org/abs/2505.20779" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI Knowledge Co-Creation</b></i>, Lin et al., <a href="https://arxiv.org/abs/2505.03105" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="novelty-significance-assessment">3.2 Novelty & Significance Assessment</h3>
</ul>

<ul>
<li><i><b>Does writing with language models reduce content diversity?</b></i>, Padmakumar et al., <a href="https://arxiv.org/abs/2309.05196" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Greater variability in judgements of the value of novel ideas</b></i>, Johnson et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>How AI ideas affect the creativity, diversity, and evolution of human ideas: evidence from a large, dynamic experiment</b></i>, Ashkinaze et al., <a href="https://arxiv.org/abs/2401.13481" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>A content-based novelty measure for scholarly publications: A proof of concept</b></i>, Wang et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Art or artifice? large language models and the false promise of creativity</b></i>, Chakrabarty et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>How ai processing delays foster creativity: Exploring research question co-creation with an llm-based agent</b></i>, Liu et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Homogenization effects of large language models on human creative ideation</b></i>, Anderson et al., <img src="https://img.shields.io/badge/Other Source-2024.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Shared imagination: Llms hallucinate alike</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2407.16604" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers</b></i>, Si et al., <a href="https://arxiv.org/abs/2409.04109" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE</b></i>, Singh et al., <a href="https://arxiv.org/abs/2410.18629" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Semi-Supervised Classification With Novelty Detection Using Support Vector Machines and Linear Discriminant Analysis</b></i>, Dove et al., <img src="https://img.shields.io/badge/Other Source-2025.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Can AI Examine Novelty of Patents?: Novelty Evaluation Based on the Correspondence between Patent Claim and Prior Art</b></i>, Ikoma et al., <a href="https://arxiv.org/abs/2502.06316" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>How do Humans and Language Models Reason About Creativity? A Comparative Analysis</b></i>, Laverghetta Jr et al., <a href="https://arxiv.org/abs/2502.03253" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Grapheval: A lightweight graph-based llm framework for idea evaluation</b></i>, Feng et al., <a href="https://arxiv.org/abs/2503.12600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>SCI-IDEA: Context-Aware Scientific Ideation Using Token and Sentence Embeddings</b></i>, Keya et al., <a href="https://arxiv.org/abs/2503.19257" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Enabling ai scientists to recognize innovation: A domain-agnostic algorithm for assessing novelty</b></i>, Wang et al., <a href="https://arxiv.org/abs/2503.01508" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>SC4ANM: Identifying optimal section combinations for automated novelty prediction in academic papers</b></i>, Wu et al., <img src="https://img.shields.io/badge/Expert Systems with Applications-2025-green" alt="Expert Systems with Applications Badge"></li>
</ul>



<h3 id="theory-analysis">3.3 Theory Analysis</h3>
<h4 id="scientific-claim-formalization">3.3.4 Scientific Claim Formalization</h4>
</ul>

<ul>
<li><i><b>LF: a foundational higher-order-logic</b></i>, Goodsell et al., <a href="https://arxiv.org/abs/2401.11050" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Natural Language Hypotheses in Scientific Papers and How to Tame Them: Suggested Steps for Formalizing Complex Scientific Claims</b></i>, Heger et al., <img src="https://img.shields.io/badge/Other Source-2024.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning</b></i>, Yan et al., <a href="https://arxiv.org/abs/2502.02871" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciclaimhunt: A large dataset for evidence-based scientific claim verification</b></i>, Kumar et al., <a href="https://arxiv.org/abs/2502.10003" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards Effective Extraction and Evaluation of Factual Claims</b></i>, Metropolitansky et al., <a href="https://arxiv.org/abs/2502.10855" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>NSF-SciFy: Mining the NSF Awards Database for Scientific Claims</b></i>, Rao et al., <a href="https://arxiv.org/abs/2503.08600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks</b></i>, Ganguly et al., <a href="https://arxiv.org/abs/2505.20047" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Valsci: an open-source, self-hostable literature review utility for automated large-batch scientific claim verification using large language models</b></i>, Edelman et al., <img src="https://img.shields.io/badge/BMC bioinformatics-2025-green" alt="BMC bioinformatics Badge"></li>
</ul>

<h4 id="scientific-evidence-collection">3.3.5 Scientific Evidence Collection</h4>
</ul>

<ul>
<li><i><b>MultiVerS: Improving scientific claim verification with weak supervision and full-document context</b></i>, Wadden et al., <a href="https://arxiv.org/abs/2112.01640" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Missing counter-evidence renders NLP fact-checking unrealistic for misinformation</b></i>, Glockner et al., <a href="https://arxiv.org/abs/2210.13865" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Investigating zero-and few-shot generalization in fact verification</b></i>, Pan et al., <a href="https://arxiv.org/abs/2309.09444" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Comparing knowledge sources for open-domain scientific claim verification</b></i>, Vladika et al., <a href="https://arxiv.org/abs/2402.02844" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Understanding Fine-grained Distortions in Reports of Scientific Findings</b></i>, W{\"u}hrl et al., <a href="https://arxiv.org/abs/2402.12431" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Improving health question answering with reliable and time-aware evidence retrieval</b></i>, Vladika et al., <a href="https://arxiv.org/abs/2404.08359" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Zero-shot scientific claim verification using LLMs and citation text</b></i>, Alvarez et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Grounding fallacies misrepresenting scientific publications in evidence</b></i>, Glockner et al., <a href="https://arxiv.org/abs/2408.12812" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Can foundation models actively gather information in interactive environments to test hypotheses?</b></i>, Ke et al., <a href="https://arxiv.org/abs/2412.06438" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>LLM-based Corroborating and Refuting Evidence Retrieval for Scientific Claim Verification</b></i>, Wang et al., <a href="https://arxiv.org/abs/2503.07937" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>SciClaims: An End-to-End Generative System for Biomedical Claim Analysis</b></i>, Ortega et al., <a href="https://arxiv.org/abs/2503.18526" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="scientific-verification-analysis">3.3.6 Scientific Verification Analysis</h4>
</ul>

<ul>
<li><i><b>Proofver: Natural logic theorem proving for fact verification</b></i>, Krishna et al., <img src="https://img.shields.io/badge/TACL-2022-green" alt="TACL Badge"></li>
<li><i><b>The state of human-centered NLP technology for fact-checking</b></i>, Das et al., <img src="https://img.shields.io/badge/Information processing & management-2023-green" alt="Information processing & management Badge"></li>
<li><i><b>aedFaCT: Scientific Fact-Checking Made Easier via Semi-Automatic Discovery of Relevant Expert Opinions</b></i>, Altuncu et al., <a href="https://arxiv.org/abs/2305.07796" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>FactKG: Fact verification via reasoning on knowledge graphs</b></i>, Kim et al., <a href="https://arxiv.org/abs/2305.06590" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Fact-checking complex claims with program-guided reasoning</b></i>, Pan et al., <a href="https://arxiv.org/abs/2305.12744" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Prompt to be consistent is better than self-consistent? few-shot and zero-shot fact verification with pre-trained language models</b></i>, Zeng et al., <a href="https://arxiv.org/abs/2306.02569" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Unsupervised Pretraining for Fact Verification by Language Model Distillation</b></i>, Bazaga et al., <a href="https://arxiv.org/abs/2309.16540" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards llm-based fact verification on news claims with a hierarchical step-by-step prompting method</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2310.00305" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Characterizing and Verifying Scientific Claims: Qualitative Causal Structure is All You Need</b></i>, Wu et al., <img src="https://img.shields.io/badge/EMNLP-2023-green" alt="EMNLP Badge"></li>
<li><i><b>Can Large Language Models Detect Misinformation in Scientific News Reporting?</b></i>, Cao et al., <a href="https://arxiv.org/abs/2402.14268" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>What makes medical claims (un) verifiable? analyzing entity and relation properties for fact verification</b></i>, W{\"u}hrl et al., <a href="https://arxiv.org/abs/2402.01360" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>ClaimVer: Explainable claim-level verification and evidence attribution of text through knowledge graphs</b></i>, Dammu et al., <a href="https://arxiv.org/abs/2403.09724" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Generating fact checking explanations</b></i>, Atanasova et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>MAGIC: Multi-Argument Generation with Self-Refinement for Domain Generalization in Automatic Fact-Checking</b></i>, Kao et al., <img src="https://img.shields.io/badge/COLING-2024-green" alt="COLING Badge"></li>
<li><i><b>Robust Claim Verification Through Fact Detection</b></i>, Jafari et al., <a href="https://arxiv.org/abs/2407.18367" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated justification production for claim veracity in fact checking: A survey on architectures and approaches</b></i>, Eldifrawi et al., <a href="https://arxiv.org/abs/2407.12853" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhancing natural language inference performance with knowledge graph for COVID-19 automated fact-checking in Indonesian language</b></i>, Muharram et al., <a href="https://arxiv.org/abs/2409.00061" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Augmenting the Veracity and Explanations of Complex Fact Checking via Iterative Self-Revision with LLMs</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2410.15135" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts</b></i>, Braun et al., <a href="https://arxiv.org/abs/2412.10510" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding</b></i>, Ku et al., <a href="https://arxiv.org/abs/2502.19400" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Explainable Biomedical Claim Verification with Large Language Models</b></i>, Liang et al., <a href="https://arxiv.org/abs/2502.21014" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?</b></i>, GX-Chen et al., <a href="https://arxiv.org/abs/2505.09614" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="theorem-proving">3.3.7 Theorem Proving</h4>
</ul>

<ul>
<li><i><b>Generative language modeling for automated theorem proving</b></i>, Polu et al., <a href="https://arxiv.org/abs/2009.03393" target="_blank"><img src="https://img.shields.io/badge/arXiv-2020.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Draft, sketch, and prove: Guiding formal theorem provers with informal proofs</b></i>, Jiang et al., <a href="https://arxiv.org/abs/2210.12283" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Hypertree proof search for neural theorem proving</b></i>, Lample et al., <img src="https://img.shields.io/badge/NeurIPS-2022-green" alt="NeurIPS Badge"></li>
<li><i><b>Thor: Wielding hammers to integrate language models and automated theorem provers</b></i>, Jiang et al., <img src="https://img.shields.io/badge/NeurIPS-2022-green" alt="NeurIPS Badge"></li>
<li><i><b>Decomposing the enigma: Subgoal-based demonstration learning for formal theorem proving</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2305.16366" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Dt-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function</b></i>, Wang et al., <img src="https://img.shields.io/badge/ACL-2023-green" alt="ACL Badge"></li>
<li><i><b>Lego-prover: Neural theorem proving with growing libraries</b></i>, Wang et al., <a href="https://arxiv.org/abs/2310.00656" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Baldur: Whole-proof generation and repair with large language models</b></i>, First et al., <img src="https://img.shields.io/badge/Other Source-2023.11-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Mustard: Mastering uniform synthesis of theorem and proof data</b></i>, Huang et al., <a href="https://arxiv.org/abs/2402.08957" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey on deep learning for theorem proving</b></i>, Li et al., <a href="https://arxiv.org/abs/2404.09939" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards large language models as copilots for theorem proving in lean</b></i>, Song et al., <a href="https://arxiv.org/abs/2404.12534" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Proving theorems recursively</b></i>, Wang et al., <a href="https://arxiv.org/abs/2405.14414" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Deepseek-prover: Advancing theorem proving in llms through large-scale synthetic data</b></i>, Xin et al., <a href="https://arxiv.org/abs/2405.14333" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Lean-star: Learning to interleave thinking and proving</b></i>, Lin et al., <a href="https://arxiv.org/abs/2407.10040" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Data for mathematical copilots: Better ways of presenting proofs for machine learning</b></i>, Frieder et al., <a href="https://arxiv.org/abs/2412.15184" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Deep Active Learning based Experimental Design to Uncover Synergistic Genetic Interactions for Host Targeted Therapeutics</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2502.01012" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Discovering Symbolic Differential Equations with Symmetry Invariants</b></i>, Yang et al., <a href="https://arxiv.org/abs/2505.12083" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="scientific-experiment-conduction">3.4 Scientific Experiment Conduction</h3>
<h4 id="experiment-design">3.4.8 Experiment Design</h4>
</ul>

<b>Semi-Automatic Experiment Design</b>
<ul>
<li><i><b>AI-assisted inverse design of sequence-ordered high intrinsic thermal conductivity polymers</b></i>, Huang et al., <img src="https://img.shields.io/badge/Materials Today Physics-2024-green" alt="Materials Today Physics Badge"></li>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Meta-Designing Quantum Experiments with Language Models</b></i>, Arlt et al., <a href="https://arxiv.org/abs/2406.02470" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>The application of artificial intelligence-assisted technology in cultural and creative product design</b></i>, Liang et al., <img src="https://img.shields.io/badge/Scientific Reports-2024-green" alt="Scientific Reports Badge"></li>
<li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework for Scientific Discovery</b></i>, Craig et al., <a href="https://aclanthology.org/2025.aisd-main.3/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
</ul>

<b>Full-Automatic Experiment Design</b>
<ul>
<li><i><b>Researchagent: Iterative research idea generation over scientific literature with large language models</b></i>, Baek et al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Biodiscoveryagent: An ai agent for designing genetic perturbation experiments</b></i>, Roohani et al., <a href="https://arxiv.org/abs/2405.17631" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation</b></i>, Swanson et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>Large Language Model Assisted Experiment Design with Generative Human-Behavior Agents</b></i>, Liu et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Carl Technical Report</b></i>, Institute et al., <a href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>Zochi Technical Report</b></i>, AI et al., <a href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Robin: A multi-agent system for automating scientific discovery</b></i>, Ghareeb et al., <a href="https://arxiv.org/abs/2505.13400" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning</b></i>, Ghafarollahi et al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-assisted design of experiments at the frontiers of computation: methods and new perspectives</b></i>, Vischia et al., <a href="https://arxiv.org/abs/2501.04448" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling Discovery of New Ionizable Lipid Designs for mRNA Delivery</b></i>, Cui et al., <img src="https://img.shields.io/badge/BioRxiv-2025-green" alt="BioRxiv Badge"></li>
<li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a href="https://arxiv.org/abs/2502.18864" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="pre-experiment-estimation">3.4.9 Pre-Experiment Estimation</h4>
</ul>

<b>Evaluative Prediction</b>
<ul>
<li><i><b>DeepCRE: Transforming Drug R&D via AI-Driven Cross-drug Response Evaluation</b></i>, Wu et al., <a href="https://arxiv.org/abs/2403.03768" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Physical formula enhanced multi-task learning for pharmacokinetics prediction</b></i>, Li et al., <a href="https://arxiv.org/abs/2404.10354" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific workflows</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2406.06357" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Unimatch: Universal matching from atom to task for few-shot drug discovery</b></i>, Li et al., <a href="https://arxiv.org/abs/2502.12453" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling Discovery of New Ionizable Lipid Designs for mRNA Delivery</b></i>, Cui et al., <img src="https://img.shields.io/badge/BioRxiv-2025-green" alt="BioRxiv Badge"></li>
<li><i><b>Predicting Empirical AI Research Outcomes with Language Models</b></i>, Wen et al., <a href="https://arxiv.org/abs/2506.00794" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models surpass human experts in predicting neuroscience results</b></i>, Luo et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
</ul>

<b>Exploratory Forecasting</b>
<ul>
<li><i><b>Automatic chemical design using a data-driven continuous representation of molecules</b></i>, G{\'o}mez-Bombarelli et al., <img src="https://img.shields.io/badge/ACS central science-2018-green" alt="ACS central science Badge"></li>
<li><i><b>MolGAN: An implicit generative model for small molecular graphs</b></i>, De Cao et al., <a href="https://arxiv.org/abs/1805.11973" target="_blank"><img src="https://img.shields.io/badge/arXiv-2018.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Google DeepMind's AI Dreamed Up 380,000 New Materials. The Next Challenge Is Making Them</b></i>, Barber et al., <a href="https://www.wired.com/story/an-ai-dreamed-up-380000-new-materials-the-next-challenge-is-making-them/" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.11-blue" alt="PDF Badge"></a></li>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific workflows</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2406.06357" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation</b></i>, Swanson et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a href="https://arxiv.org/abs/2502.18864" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>FlavorDiffusion: Modeling Food-Chemical Interactions with Diffusion</b></i>, Seo et al., <a href="https://aclanthology.org/2025.aisd-main.7/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>MOOSE-Chem3: Toward Experiment-Guided Hypothesis Ranking via Simulated Experimental Feedback</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.17873" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="experiment-management">3.4.10 Experiment Management</h4>
</ul>

<b>Open-Loop Management</b>
<ul>
<li><i><b>The future of self-driving laboratories: from human in the loop interactive AI to gamification</b></i>, Hysmith et al., <img src="https://img.shields.io/badge/Digital Discovery-2024-green" alt="Digital Discovery Badge"></li>
<li><i><b>Self-driving labs are the new AI asset</b></i>, {Axios} et al., <a href="https://www.axios.com/2024/08/09/ai-self-driving-science-labs-research" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>DeepMind and BioNTech build AI lab assistants for scientific research</b></i>, Times} et al., <a href="https://www.ft.com/content/64b1bb33-095e-4cc5-a911-50df76fa3d1d" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.10-blue" alt="PDF Badge"></a></li>
<li><i><b>Autonomous platform for solution processing of electronic polymers</b></i>, Wang et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
<li><i><b>Machine learning-led semi-automated medium optimization reveals salt as key for flaviolin production in Pseudomonas putida</b></i>, Zournas et al., <img src="https://img.shields.io/badge/Communications Biology-2025-green" alt="Communications Biology Badge"></li>
</ul>

<b>Close-Loop Management</b>
<ul>
<li><i><b>Functional genomic hypothesis generation and experimentation by a robot scientist</b></i>, King et al., <img src="https://img.shields.io/badge/Nature-2004-green" alt="Nature Badge"></li>
<li><i><b>Self-driving laboratory for accelerated discovery of thin-film materials</b></i>, MacLeod et al., <img src="https://img.shields.io/badge/Science Advances-2020-green" alt="Science Advances Badge"></li>
<li><i><b>Self-driving laboratories for chemistry and materials science</b></i>, Tom et al., <img src="https://img.shields.io/badge/Chemical Reviews-2024-green" alt="Chemical Reviews Badge"></li>
<li><i><b>Autonomous platform for solution processing of electronic polymers</b></i>, Wang et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
<li><i><b>Self-driving laboratory platform for many-objective self-optimisation of polymer nanoparticle synthesis with cloud-integrated machine learning and orthogonal online analytics</b></i>, Knox et al., <img src="https://img.shields.io/badge/Polymer Chemistry-2025-green" alt="Polymer Chemistry Badge"></li>
</ul>

<ul>
<li><i><b>Transforming science labs into automated factories of discovery</b></i>, Angelopoulos et al., <img src="https://img.shields.io/badge/Science Robotics-2024-green" alt="Science Robotics Badge"></li>
<li><i><b>Development of an Automated Workflow for Screening the Assembly and Host--Guest Behavior of Metal-Organic Cages Towards Accelerated Discovery</b></i>, Basford et al., <img src="https://img.shields.io/badge/Angewandte Chemie International Edition-2024-green" alt="Angewandte Chemie International Edition Badge"></li>
<li><i><b>AI Driven Experiment Calibration and Control</b></i>, Britton et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agents for self-driving laboratories applied to quantum computing</b></i>, Cao et al., <a href="https://arxiv.org/abs/2412.07978" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Intelligent experiments through real-time AI: Fast Data Processing and Autonomous Detector Control for sPHENIX and future EIC detectors</b></i>, Kvapil et al., <a href="https://arxiv.org/abs/2501.04845" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence meets laboratory automation in discovery and synthesis of metal--organic frameworks: A review</b></i>, Zhao et al., <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agents for Change: Artificial Intelligent Workflows for Quantitative Clinical Pharmacology and Translational Sciences</b></i>, Shahin et al., <img src="https://img.shields.io/badge/Clinical and Translational Science-2025-green" alt="Clinical and Translational Science Badge"></li>
<li><i><b>Science acceleration and accessibility with self-driving labs</b></i>, Canty et al., <img src="https://img.shields.io/badge/Nature Communications-2025-green" alt="Nature Communications Badge"></li>
<li><i><b>Accelerating drug discovery with Artificial: a whole-lab orchestration and scheduling system for self-driving labs</b></i>, Fehlis et al., <a href="https://arxiv.org/abs/2504.00986" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Uncovering Bottlenecks and Optimizing Scientific Lab Workflows with Cycle Time Reduction Agents</b></i>, Fehlis et al., <a href="https://arxiv.org/abs/2505.21534" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Perspective on Utilizing Foundation Models for Laboratory Automation in Materials Research</b></i>, Hatakeyama-Sato et al., <a href="https://arxiv.org/abs/2506.12312" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="experimental-conduction">3.4.11 Experimental Conduction</h4>
</ul>

<b>Automated Machine Learning Experiment Conduction</b>
<ul>
<li><i><b>AIDE: Human-Level Performance on Data Science Competitions</b></i>, Dominik et al., <a href="https://www.weco.ai/blog/technical-report" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.04-blue" alt="PDF Badge"></a></li>
<li><i><b>Automl-gpt: Automatic machine learning with gpt</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2305.02499" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Automl in the age of large language models: Current challenges, future opportunities and risks</b></i>, Tornede et al., <a href="https://arxiv.org/abs/2306.08107" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Opendevin: An open platform for ai software developers as generalist agents</b></i>, Wang et al., <a href="https://arxiv.org/abs/2407.16741" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Mlr-copilot: Autonomous machine learning research based on large language models agents</b></i>, Li et al., <a href="https://arxiv.org/abs/2408.14033" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Autokaggle: A multi-agent framework for autonomous data science competitions</b></i>, Li et al., <a href="https://arxiv.org/abs/2410.20424" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models orchestrating structured reasoning achieve kaggle grandmaster level</b></i>, Grosnit et al., <a href="https://arxiv.org/abs/2411.03562" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2504.09702" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2505.20662" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Variable Extraction for Model Recovery in Scientific Literature</b></i>, Liu et al., <a href="https://aclanthology.org/2025.aisd-main.1/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>AlphaEvolve: A coding agent for scientific and algorithmic discovery</b></i>, Novikov et al., <img src="https://img.shields.io/badge/Google DeepMind-2025-green" alt="Google DeepMind Badge"></li>
</ul>

<b>Real-world Experimental Simulation & Conduction.</b>
<ul>
<li><i><b>Large language models can self-improve</b></i>, Huang et al., <a href="https://arxiv.org/abs/2210.11610" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Mlcopilot: Unleashing the power of large language models in solving machine learning tasks</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2304.14979" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Training socially aligned language models in simulated human society</b></i>, Liu et al., <a href="https://arxiv.org/abs/2305.16960" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Toolllm: Facilitating large language models to master 16000+ real-world apis</b></i>, Qin et al., <a href="https://arxiv.org/abs/2307.16789" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>An autonomous laboratory for the accelerated synthesis of novel materials</b></i>, Szymanski et al., <img src="https://img.shields.io/badge/Nature-2023-green" alt="Nature Badge"></li>
<li><i><b>Autonomous chemical research with large language models</b></i>, Boiko et al., <img src="https://img.shields.io/badge/Nature-2023-green" alt="Nature Badge"></li>
<li><i><b>Reflexion: Language agents with verbal reinforcement learning</b></i>, Shinn et al., <img src="https://img.shields.io/badge/NeurIPS-2023-green" alt="NeurIPS Badge"></li>
<li><i><b>Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings</b></i>, Hao et al., <img src="https://img.shields.io/badge/NeurIPS-2023-green" alt="NeurIPS Badge"></li>
<li><i><b>Toolformer: Language models can teach themselves to use tools</b></i>, Schick et al., <img src="https://img.shields.io/badge/NeurIPS-2023-green" alt="NeurIPS Badge"></li>
<li><i><b>scGPT: toward building a foundation model for single-cell multi-omics using generative AI</b></i>, Cui et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Large language model agent for hyper-parameter optimization</b></i>, Liu et al., <a href="https://arxiv.org/abs/2402.01881" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge</b></i>, Ni et al., <img src="https://img.shields.io/badge/Extreme Mechanics Letters-2024-green" alt="Extreme Mechanics Letters Badge"></li>
<li><i><b>Researchagent: Iterative research idea generation over scientific literature with large language models</b></i>, Baek et al., <a href="https://arxiv.org/abs/2404.07738" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated social science: Language models as scientist and subjects</b></i>, Manning et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Crispr-gpt: An llm agent for automated design of gene-editing experiments</b></i>, Huang et al., <a href="https://arxiv.org/abs/2404.18021" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Position: LLMs can’t plan, but can help planning in LLM-modulo frameworks</b></i>, Kambhampati et al., <img src="https://img.shields.io/badge/ICML-2024-green" alt="ICML Badge"></li>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Mlr-copilot: Autonomous machine learning research based on large language models agents</b></i>, Li et al., <a href="https://arxiv.org/abs/2408.14033" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning</b></i>, Ghafarollahi et al., <a href="https://arxiv.org/abs/2409.05556" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Wrong-of-thought: An integrated reasoning framework with multi-perspective verification and wrong information</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2410.04463" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses about Real-World Entities</b></i>, Zabaleta et al., <a href="https://arxiv.org/abs/2411.18071" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>An automatic end-to-end chemical synthesis development platform powered by large language models</b></i>, Ruan et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards LLM-Driven Multi-Agent Pipeline for Drug Discovery: Neurodegenerative Diseases Case Study</b></i>, Solovev et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents</b></i>, Mou et al., <a href="https://arxiv.org/abs/2412.03563" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>On Evaluating LLMs' Capabilities as Functional Approximators: A Bayesian Evaluation Framework</b></i>, Siddiqui et al., <a href="https://aclanthology.org/2025.coling-main.388/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.01-blue" alt="PDF Badge"></a></li>
<li><i><b>PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents</b></i>, Lee et al., <a href="https://arxiv.org/abs/2501.01594" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback</b></i>, Yuan et al., <a href="https://arxiv.org/abs/2501.03916" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective</b></i>, Peng et al., <a href="https://arxiv.org/abs/2503.13413" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Simulating cooperative prosocial behavior with multi-agent LLMs: Evidence and mechanisms for AI agents to inform policy decisions</b></i>, Sreedhar et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Reinforcing clinical decision support through multi-agent systems and ethical ai governance</b></i>, Chen et al., <a href="https://arxiv.org/abs/2504.03699" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>OpenFOAMGPT 2.0: end-to-end, trustworthy automation for computational fluid dynamics</b></i>, Feng et al., <a href="https://arxiv.org/abs/2504.19338" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Researchcodeagent: An llm multi-agent system for automated codification of research methodologies</b></i>, Gandhi et al., <a href="https://arxiv.org/abs/2504.20117" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search</b></i>, Yamada et al., <a href="https://arxiv.org/abs/2504.08066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>MooseAgent: A LLM Based Multi-agent Framework for Automating Moose Simulation</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2504.08621" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Owl: Optimized workforce learning for general multi-agent assistance in real-world task automation</b></i>, Hu et al., <a href="https://arxiv.org/abs/2505.23885" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="experimental-analysis">3.4.12 Experimental Analysis</h4>
</ul>

<b>Automated Evaluation Metrics</b>
<ul>
<li><i><b>Eight years of AutoML: categorisation, review and trends</b></i>, Barbudo et al., <img src="https://img.shields.io/badge/Knowledge and Information Systems-2023-green" alt="Knowledge and Information Systems Badge"></li>
<li><i><b>Efficient bayesian learning curve extrapolation using prior-data fitted networks</b></i>, Adriaensen et al., <img src="https://img.shields.io/badge/NeurIPS-2023-green" alt="NeurIPS Badge"></li>
<li><i><b>Automated machine learning: past, present and future</b></i>, Baratchi et al., <img src="https://img.shields.io/badge/Artificial intelligence review-2024-green" alt="Artificial intelligence review Badge"></li>
</ul>

<b>Theoretical Consistency Analysis</b>
<ul>
<li><i><b>Variable Extraction for Model Recovery in Scientific Literature</b></i>, Liu et al., <a href="https://aclanthology.org/2025.aisd-main.1/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2505.20662" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Exploratory Analysis</b>
<ul>
<li><i><b>HeLM: Highlighted Evidence augmented Language Model for Enhanced Table-to-Text Generation</b></i>, Bian et al., <a href="https://arxiv.org/abs/2311.08896" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Table meets llm: Can large language models understand structured table data? a benchmark and empirical study</b></i>, Sui et al., <img src="https://img.shields.io/badge/Other Source-2024.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning</b></i>, Xing et al., <a href="https://arxiv.org/abs/2410.12164" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>LLM Based Exploratory Data Analysis Using BigQuery Data Canvas</b></i>, Chaudhuri et al., <a href="https://medium.com/google-cloud/llm-based-exploratory-data-analysis-using-bigquery-data-canvas-42fbecb9f009" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.10-blue" alt="PDF Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>Toward machine learning optimization of experimental design</b></i>, Baydin et al., <img src="https://img.shields.io/badge/Nuclear Physics News-2021-green" alt="Nuclear Physics News Badge"></li>
<li><i><b>AI-assisted design of experiments at the frontiers of computation: methods and new perspectives</b></i>, Vischia et al., <a href="https://arxiv.org/abs/2501.04448" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.12039" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>EXP-Bench: Can AI Conduct AI Research Experiments?</b></i>, Kon et al., <a href="https://arxiv.org/abs/2505.24785" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AI Scientists Fail Without Strong Implementation Capability</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2506.01372" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="full-automatic-discovery">3.5 Full-Automatic Discovery</h3>
</ul>

<ul>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Aviary: training language agents on challenging scientific tasks</b></i>, Narayanan et al., <a href="https://arxiv.org/abs/2412.21154" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback</b></i>, Yuan et al., <a href="https://arxiv.org/abs/2501.03916" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Autonomous Microscopy Experiments through Large Language Model Agents</b></i>, Mandal et al., <a href="https://arxiv.org/abs/2501.10385" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Curie: Toward rigorous and automated scientific experimentation with ai agents</b></i>, Kon et al., <a href="https://arxiv.org/abs/2502.16069" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>DORA AI Scientist: Multi-agent Virtual Research Team for Scientific Exploration Discovery and Automated Report Generation</b></i>, Naumov et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>Carl Technical Report</b></i>, Institute et al., <a href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Zochi Technical Report</b></i>, AI et al., <a href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>NovelSeek: When Agent Becomes the Scientist--Building Closed-Loop System from Hypothesis to Verification</b></i>, Team et al., <a href="https://arxiv.org/abs/2505.16938" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists</b></i>, Li et al., <a href="https://arxiv.org/abs/2506.08140" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>VISION: A modular AI assistant for natural human-instrument interaction at scientific user facilities</b></i>, Mathur et al., <img src="https://img.shields.io/badge/Other Source-2025.06-lightgrey" alt="Other Source Badge"></li>
</ul>

</ul>

<ul>
<li><i><b>Scientific discovery in the age of artificial intelligence</b></i>, Wang et al., <img src="https://img.shields.io/badge/Nature-2023-green" alt="Nature Badge"></li>
<li><i><b>Beyond Benchmarking: Automated Capability Discovery via Model Self-Exploration</b></i>, Lu et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>AIRUS: a simple workflow for AI-assisted exploration of scientific data</b></i>, Harris et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>On the Rise of New Mathematical Spaces and Towards AI-Driven Scientific Discovery</b></i>, Raeini et al., <img src="https://img.shields.io/badge/Available at SSRN-2025-green" alt="Available at SSRN Badge"></li>
<li><i><b>From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models</b></i>, He et al., <a href="https://arxiv.org/abs/2505.21935" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Driven Discovery: The Transformative Impact of Machine Learning on Research and Development</b></i>, Roy et al., <img src="https://img.shields.io/badge/Other Source-2025.06-lightgrey" alt="Other Source Badge"></li>
</ul>
<h2 id="academic-writing">4. AI for Academic Writing</h2>


<h3 id="semi-automatic-academic-writing">4.1 Semi-Automatic Academic Writing</h3>
<img src="./assets/images/academic-writing.png" style="width: 580pt">
<h4 id="assistance-during-manuscript-preparation">4.1.1 Assistance During Manuscript Preparation</h4>
<b>Title Formulation and Optimization</b>
<ul>
<li><i><b>Personalized Graph-Based Retrieval for Large Language Models</b></i>, Au et al., <a href="https://arxiv.org/abs/2501.02157" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Generating Accurate and Engaging Research Paper Titles Using NLP Techniques</b></i>, Bikku et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>MoDeST: A dataset for Multi Domain Scientific Title Generation</b></i>, B{\"o}l{\"u}c{\"u} et al., <img src="https://img.shields.io/badge/Knowledge-Based Systems-2025-green" alt="Knowledge-Based Systems Badge"></li>
<li><i><b>Can pre-trained language models generate titles for research papers?</b></i>, Rehman et al., <img src="https://img.shields.io/badge/Other Source-2025.12-lightgrey" alt="Other Source Badge"></li>
</ul>

<b>Overall Logical Structure Guidance</b>
<ul>
<li><i><b>LalaEval: A Holistic Human Evaluation Framework for Domain-Specific Large Language Models</b></i>, Sun et al., <img src="https://img.shields.io/badge/CoLM-2024-green" alt="CoLM Badge"></li>
<li><i><b>LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts</b></i>, Hashemi et al., <a href="https://aclanthology.org/2024.acl-long.745/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
</ul>

<h4 id="assistance-during-manuscript-writing">4.1.2 Assistance During Manuscript Writing</h4>
</ul>

<b>Drawing Figures and Charts</b>
<ul>
<li><i><b>Text2chart: A multi-staged chart generator from natural language text</b></i>, Rashid et al., <img src="https://img.shields.io/badge/Other Source-2022.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>ChartReader: A unified framework for chart derendering and comprehension without heuristic rules</b></i>, Cheng et al., <img src="https://img.shields.io/badge/ICCV-2023-green" alt="ICCV Badge"></li>
<li><i><b>Figgen: Text to scientific figure generation</b></i>, Rodriguez et al., <a href="https://arxiv.org/abs/2306.00800" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Automatikz: Text-guided synthesis of scientific vector graphics with tikz</b></i>, Belouadi et al., <a href="https://arxiv.org/abs/2310.00367" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Scicapenter: Supporting caption composition for scientific figures with machine-generated captions and ratings</b></i>, Hsu et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>ChartFormer: A large vision language model for converting chart images into tactile accessible SVGs</b></i>, Moured et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Figuring out Figures: Using Textual References to Caption Scientific Figures</b></i>, Cao et al., <a href="https://arxiv.org/abs/2407.11008" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification</b></i>, Hogan et al., <a href="https://arxiv.org/abs/2410.21480" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2412.02368" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Chartcoder: Advancing multimodal large language model for chart-to-code generation</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2501.06598" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Understanding How Paper Writers Use AI-Generated Captions in Figure Caption Writing</b></i>, Yin et al., <a href="https://arxiv.org/abs/2501.06317" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Multi-LLM Collaborative Caption Generation in Scientific Documents</b></i>, Kim et al., <a href="https://arxiv.org/abs/2501.02552" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>TikZero: Zero-Shot Text-Guided Graphics Program Synthesis</b></i>, Belouadi et al., <a href="https://arxiv.org/abs/2503.11509" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2504.02906" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>StarVector: Generating scalable vector graphics code from images and text</b></i>, Rodriguez et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search</b></i>, Yamada et al., <a href="https://arxiv.org/abs/2504.08066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>How to Create Accurate Scientific Illustrations with AI in 2025</b></i>, Team et al., <a href="https://illustrae.co/blog/how-to-create-accurate-scientific-illustrations-ai" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
</ul>

<b>Formula Transcription</b>
<ul>
<li><i><b>Towards Semantic Markup of Mathematical Documents via User Interaction</b></i>, Vre{\v{c}}ar et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Automated LaTeX Code Generation from Handwritten Math Expressions Using Vision Transformer</b></i>, Sundararaj et al., <a href="https://arxiv.org/abs/2412.03853" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>LATTE: Improving Latex Recognition for Tables and Formulae with Iterative Refinement</b></i>, Jiang et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
</ul>

<b>Citation Recommendation & Integration</b>
<ul>
<li><i><b>Chronological citation recommendation with time preference</b></i>, Ma et al., <img src="https://img.shields.io/badge/Scientometrics-2021-green" alt="Scientometrics Badge"></li>
<li><i><b>When large language models meet citation: A survey</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2309.09727" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Directed Criteria Citation Recommendation and Ranking Through Link Prediction</b></i>, Watson et al., <a href="https://arxiv.org/abs/2403.18855" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation</b></i>, Roy et al., <a href="https://arxiv.org/abs/2403.08737" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>CiteBART: Learning to Generate Citations for Local Citation Recommendation</b></i>, {\c{C}}elik et al., <a href="https://arxiv.org/abs/2412.17534" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Benchmark for Evaluation and Analysis of Citation Recommendation Models</b></i>, Maharjan et al., <a href="https://arxiv.org/abs/2412.07713" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations</b></i>, Wang et al., <a href="https://arxiv.org/abs/2504.00824" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>How deep do large language models internalize scientific literature and citation practices?</b></i>, Algaba et al., <a href="https://arxiv.org/abs/2504.02767" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>SCIRGC: Multi-Granularity Citation Recommendation and Citation Sentence Preference Alignment</b></i>, Li et al., <a href="https://arxiv.org/abs/2505.20103" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards AI-assisted Academic Writing</b></i>, Liebling et al., <a href="https://aclanthology.org/2025.aisd-main.4/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
</ul>

<ul>
<li><i><b>Enhancing academic writing skills and motivation: assessing the efficacy of ChatGPT in AI-assisted language learning for EFL students</b></i>, Song et al., <img src="https://img.shields.io/badge/Frontiers in Psychology-2023-green" alt="Frontiers in Psychology Badge"></li>
<li><i><b>Human-AI collaboration patterns in AI-assisted academic writing</b></i>, Nguyen et al., <img src="https://img.shields.io/badge/Studies in Higher Education-2024-green" alt="Studies in Higher Education Badge"></li>
<li><i><b>Patterns and Purposes: A Cross-Journal Analysis of AI Tool Usage in Academic Writing</b></i>, Xu et al., <a href="https://arxiv.org/abs/2502.00632" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Divergent llm adoption and heterogeneous convergence paths in research writing</b></i>, Lin et al., <a href="https://arxiv.org/abs/2504.13629" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence-assisted academic writing: recommendations for ethical use</b></i>, Cheng et al., <img src="https://img.shields.io/badge/Advances in Simulation-2025-green" alt="Advances in Simulation Badge"></li>
</ul>

<h4 id="assistance-after-manuscript-completion">4.1.3 Assistance After Manuscript Completion</h4>
</ul>

<b>Grammar Correction</b>
<ul>
<li><i><b>Csed: A chinese semantic error diagnosis corpus</b></i>, Sun et al., <a href="https://arxiv.org/abs/2305.05183" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Neural Automated Writing Evaluation with Corrective Feedback</b></i>, Wang et al., <a href="https://arxiv.org/abs/2402.17613" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error Correction</b></i>, Wang et al., <a href="https://arxiv.org/abs/2403.17413" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Improving Grammatical Error Correction via Contextual Data Augmentation</b></i>, Wang et al., <a href="https://arxiv.org/abs/2406.17456" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>How Paperpal Enhances English Writing Quality and Improves Productivity for Japanese Academics</b></i>, George et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Transforming hematological research documentation with large language models: an approach to scientific writing and data analysis</b></i>, Yang et al., <img src="https://img.shields.io/badge/Blood research-2025-green" alt="Blood research Badge"></li>
<li><i><b>The usage of a transformer based and artificial intelligence driven multidimensional feedback system in english writing instruction</b></i>, Zheng et al., <img src="https://img.shields.io/badge/Scientific Reports-2025-green" alt="Scientific Reports Badge"></li>
</ul>

<b>Expression & Logical Revision</b>
<ul>
<li><i><b>Learning to split and rephrase from Wikipedia edit history</b></i>, Botha et al., <a href="https://arxiv.org/abs/1808.09468" target="_blank"><img src="https://img.shields.io/badge/arXiv-2018.08-red" alt="arXiv Badge"></a></li>
<li><i><b>WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling language and discourse</b></i>, Faruqui et al., <a href="https://arxiv.org/abs/1808.09422" target="_blank"><img src="https://img.shields.io/badge/arXiv-2018.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Diamonds in the rough: Generating fluent sentences from early-stage drafts for academic writing assistance</b></i>, Ito et al., <a href="https://arxiv.org/abs/1910.09180" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Text editing by command</b></i>, Faltings et al., <a href="https://arxiv.org/abs/2010.12826" target="_blank"><img src="https://img.shields.io/badge/arXiv-2020.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Wordcraft: A human-AI collaborative editor for story writing</b></i>, Coenen et al., <a href="https://arxiv.org/abs/2107.07430" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Machine-in-the-loop rewriting for creative image captioning</b></i>, Padmakumar et al., <a href="https://arxiv.org/abs/2111.04193" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision</b></i>, Du et al., <a href="https://arxiv.org/abs/2204.03685" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities</b></i>, Lee et al., <img src="https://img.shields.io/badge/Other Source-2022.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Sparks: Inspiration for science writing using language models</b></i>, Gero et al., <img src="https://img.shields.io/badge/Other Source-2022.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Techniques for supercharging academic writing with generative AI</b></i>, Lin et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Overleafcopilot: Empowering academic writing in overleaf with large language models</b></i>, Wen et al., <a href="https://arxiv.org/abs/2403.09733" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Augmenting the author: Exploring the potential of AI collaboration in academic writing</b></i>, Tu et al., <a href="https://arxiv.org/abs/2404.16071" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Step-Back Profiling: Distilling User History for Personalized Scientific Writing</b></i>, Tang et al., <a href="https://arxiv.org/abs/2406.14275" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions</b></i>, Nair et al., <a href="https://arxiv.org/abs/2410.08058" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhancing Chinese Essay Discourse Logic Evaluation Through Optimized Fine-Tuning of Large Language Models</b></i>, Song et al., <img src="https://img.shields.io/badge/NLPCC-2024-green" alt="NLPCC Badge"></li>
<li><i><b>Cocoa: Co-Planning and Co-Execution with AI Agents</b></i>, Feng et al., <a href="https://arxiv.org/abs/2412.10999" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild</b></i>, Mysore et al., <a href="https://arxiv.org/abs/2505.16023" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.11336" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>The usage of a transformer based and artificial intelligence driven multidimensional feedback system in english writing instruction</b></i>, Zheng et al., <img src="https://img.shields.io/badge/Scientific Reports-2025-green" alt="Scientific Reports Badge"></li>
<li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research Papers</b></i>, Ifargan et al., <img src="https://img.shields.io/badge/NEJM AI-2025-green" alt="NEJM AI Badge"></li>
</ul>



<h3 id="full-automatic-academic-writing">4.2 Full-Automatic Academic Writing</h3>
</ul>

<ul>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Agent laboratory: Using llm agents as research assistants</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2501.04227" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>ScholaWrite: A Dataset of End-to-End Scholarly Writing Process</b></i>, Wang et al., <a href="https://arxiv.org/abs/2502.02904" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Beyond outlining: Heterogeneous recursive planning for adaptive long-form writing with language models</b></i>, Xiong et al., <a href="https://arxiv.org/abs/2503.08275" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>AgentRxiv: Towards Collaborative Autonomous Research</b></i>, Schmidgall et al., <a href="https://arxiv.org/abs/2503.18102" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Zochi Technical Report</b></i>, AI et al., <a href="https://github.com/IntologyAI/Zochi/blob/main/Zochi_Technical_Report.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>Carl Technical Report</b></i>, Institute et al., <a href="https://drive.google.com/file/d/1iVedOdZDuEdjS4lcm9Z7i8oEDGWfzVJq/view" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.03-blue" alt="PDF Badge"></a></li>
<li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search</b></i>, Yamada et al., <a href="https://arxiv.org/abs/2504.08066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>Using artificial intelligence in academic writing and research: An essential productivity tool</b></i>, Khalifa et al., <img src="https://img.shields.io/badge/Other Source-2024.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Human-LLM Coevolution: Evidence from Academic Writing</b></i>, Geng et al., <a href="https://arxiv.org/abs/2502.09606" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models penetration in scholarly writing and peer review</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2502.11193" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>And Plato met ChatGPT: an ethical reflection on the use of chatbots in scientific research writing, with a particular focus on the social sciences</b></i>, Calderon et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
</ul>
<h2 id="academic-peer-reviewing">5. AI for Academic Peer Reviewing</h2>


<h3 id="pre-review">5.1 Pre-Review</h3>
<img src="./assets/images/academic-peer-reviewing.png" style="width: 580pt">
<h4 id="desk-review">5.1.1 Desk-Review</h4>
<ul>
<li><i><b>How to Make Peer Review Recommendations and Decisions</b></i>, Society et al., <a href="https://www.computer.org/publications/making-peer-review-recommendations" target="_blank"><img src="https://img.shields.io/badge/Other Source-.00-lightgrey" alt="Other Source Badge"></a></li>
<li><i><b>Helping editors find reviewers</b></i>, Tedford et al., <a href="https://www.elsevier.com/connect/helping-editors-find-reviewers" target="_blank"><img src="https://img.shields.io/badge/Other Source-2015.09-lightgrey" alt="Other Source Badge"></a></li>
<li><i><b>Snapp: Springer Nature's next-generation peer review system</b></i>, Nature et al., <a href="https://www.springernature.com/gp/snapp" target="_blank"><img src="https://img.shields.io/badge/Other Source-2023.12-lightgrey" alt="Other Source Badge"></a></li>
<li><i><b>Matching papers and reviewers at large conferences</b></i>, Leyton-Brown et al., <img src="https://img.shields.io/badge/Artificial Intelligence-2024-green" alt="Artificial Intelligence Badge"></li>
<li><i><b>Streamlining the review process: AI-generated annotations in research manuscripts</b></i>, D{\'\i}az et al., <a href="https://arxiv.org/abs/2412.00281" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence in peer review: enhancing efficiency while preserving integrity</b></i>, Doskaliuk et al., <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Enhancing Academic Decision-Making: A Pilot Study of AI-Supported Journal Selection in Higher Education</b></i>, Farber et al., <img src="https://img.shields.io/badge/Innovative Higher Education-2025-green" alt="Innovative Higher Education Badge"></li>
</ul>

<h4 id="reviewer-matching">5.1.2 Reviewer Matching</h4>
</ul>

<ul>
<li><i><b>A framework for optimizing paper matching</b></i>, Charlin et al., <img src="https://img.shields.io/badge/UAI-2011-green" alt="UAI Badge"></li>
<li><i><b>The Toronto paper matching system: an automated paper-reviewer assignment system</b></i>, Charlin et al., <img src="https://img.shields.io/badge/Other Source-2013.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Pistis: A conflict of interest declaration and detection system for peer review management</b></i>, Wu et al., <img src="https://img.shields.io/badge/Other Source-2018.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>An automated conflict of interest based greedy approach for conference paper assignment system</b></i>, Pradhan et al., <img src="https://img.shields.io/badge/Journal of Informetrics-2020-green" alt="Journal of Informetrics Badge"></li>
<li><i><b>Matching papers and reviewers at large conferences</b></i>, Leyton-Brown et al., <img src="https://img.shields.io/badge/Artificial Intelligence-2024-green" alt="Artificial Intelligence Badge"></li>
<li><i><b>Autonomous Machine Learning-Based Peer Reviewer Selection System</b></i>, Aitymbetov et al., <img src="https://img.shields.io/badge/COLING-2025-green" alt="COLING Badge"></li>
<li><i><b>Automated Research Review Support Using Machine Learning, Large Language Models, and Natural Language Processing</b></i>, Pendyala et al., <img src="https://img.shields.io/badge/Electronics-2025-green" alt="Electronics Badge"></li>
<li><i><b>Peer review expert group recommendation: A multi-subject coverage-based approach</b></i>, Fu et al., <img src="https://img.shields.io/badge/Expert Systems with Applications-2025-green" alt="Expert Systems with Applications Badge"></li>
</ul>



<h3 id="in-review">5.2 In-Review</h3>
<h4 id="peer-review">5.2.3 Peer-Review</h4>
</ul>

<b>Score Prediction</b>
<ul>
<li><i><b>ALL-IN-ONE: Multi-Task Learning BERT Models for Evaluating Peer Assessments.</b></i>, Jia et al., <img src="https://img.shields.io/badge/Other Source-2021.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>The quality assist: A technology-assisted peer review based on citation functions to predict the paper quality</b></i>, Basuki et al., <img src="https://img.shields.io/badge/IEEE Access-2022-green" alt="IEEE Access Badge"></li>
<li><i><b>Exploiting labeled and unlabeled data via transformer fine-tuning for peer-review score prediction</b></i>, Muangkammuen et al., <img src="https://img.shields.io/badge/EMNLP Findings-2022-green" alt="EMNLP Findings Badge"></li>
<li><i><b>RelevAI-Reviewer: A Benchmark on AI Reviewers for Survey Paper Relevance</b></i>, Couto et al., <a href="https://arxiv.org/abs/2406.10294" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>Comment Generation</b>
<ul>
<li><i><b>Kid-review: knowledge-guided scientific review generation with oracle pre-training</b></i>, Yuan et al., <img src="https://img.shields.io/badge/AAAI-2022-green" alt="AAAI Badge"></li>
<li><i><b>Gpt4 is slightly helpful for peer-review assistance: A pilot study</b></i>, Robertson et al., <a href="https://arxiv.org/abs/2307.05492" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Marg: Multi-agent review generation for scientific papers</b></i>, D'Arcy et al., <a href="https://arxiv.org/abs/2401.04259" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Peer review as a multi-turn and long-context dialogue with role-based interactions</b></i>, Tan et al., <a href="https://arxiv.org/abs/2406.05688" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Agentreview: Exploring peer review dynamics with llm agents</b></i>, Jin et al., <a href="https://arxiv.org/abs/2406.12708" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Can large language models provide useful feedback on research papers? A large-scale empirical analysis</b></i>, Liang et al., <img src="https://img.shields.io/badge/NEJM AI-2024-green" alt="NEJM AI Badge"></li>
<li><i><b>Automated Focused Feedback Generation for Scientific Writing Assistance</b></i>, Chamoun et al., <a href="https://aclanthology.org/2024.findings-acl.580/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>SEAGraph: Unveiling the Whole Story of Paper Review Comments</b></i>, Yu et al., <a href="https://arxiv.org/abs/2412.11939" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search</b></i>, Yamada et al., <a href="https://arxiv.org/abs/2504.08066" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<b>Unified Generation</b>
<ul>
<li><i><b>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications</b></i>, Kang et al., <img src="https://img.shields.io/badge/NAACL-2018-green" alt="NAACL Badge"></li>
<li><i><b>Peerassist: leveraging on paper-review interactions to predict peer review decisions</b></i>, Bharti et al., <img src="https://img.shields.io/badge/Other Source-2021.11-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Marg: Multi-agent review generation for scientific papers</b></i>, D'Arcy et al., <a href="https://arxiv.org/abs/2401.04259" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Peer review as a multi-turn and long-context dialogue with role-based interactions</b></i>, Tan et al., <a href="https://arxiv.org/abs/2406.05688" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated review generation method based on large language models</b></i>, Wu et al., <a href="https://arxiv.org/abs/2407.20906" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Driven review systems: evaluating LLMs in scalable and bias-aware academic reviews</b></i>, Tyser et al., <a href="https://arxiv.org/abs/2408.10365" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>MAMORX: Multi-agent multi-modal scientific review generation with external knowledge</b></i>, Taechoyotin et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Cycleresearcher: Improving automated research via automated review</b></i>, Weng et al., <a href="https://arxiv.org/abs/2411.00816" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews</b></i>, Idahl et al., <a href="https://arxiv.org/abs/2412.11948" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>The role of large language models in the peer-review process: opportunities and challenges for medical journal reviewers and editors</b></i>, Lee et al., <img src="https://img.shields.io/badge/Other Source-2025.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>PiCO: Peer Review in LLMs based on Consistency Optimization</b></i>, Ning et al., <a href="https://openreview.net/forum?id=sfQ6XpApfS" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.01-blue" alt="PDF Badge"></a></li>
<li><i><b>Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM Reviews</b></i>, Shin et al., <a href="https://arxiv.org/abs/2502.17086" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Revieweval: An evaluation framework for ai-generated reviews</b></i>, Kirtani et al., <a href="https://arxiv.org/abs/2502.11736" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Automatically Evaluating the Paper Reviewing Capability of Large Language Models</b></i>, Shin et al., <a href="https://arxiv.org/abs/2502.17086" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Deepreview: Improving llm-based paper review with human-like deep thinking process</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2503.08569" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Reviewagents: Bridging the gap between human and ai-generated paper reviews</b></i>, Gao et al., <a href="https://arxiv.org/abs/2503.08506" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Reviewing Scientific Papers for Critical Problems With Reasoning LLMs: Baseline Approaches and Automatic Evaluation</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2505.23824" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning</b></i>, Taechoyotin et al., <a href="https://arxiv.org/abs/2505.11718" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review</b></i>, Chang et al., <a href="https://arxiv.org/abs/2506.07642" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>PaperEval: A universal, quantitative, and explainable paper evaluation method powered by a multi-agent system</b></i>, Huang et al., <img src="https://img.shields.io/badge/Information Processing & Management-2025-green" alt="Information Processing & Management Badge"></li>
</ul>

<h4 id="meta-review">5.2.4 Meta-Review</h4>
</ul>

<ul>
<li><i><b>Summarizing multiple documents with conversational structure for meta-review generation</b></i>, Li et al., <a href="https://arxiv.org/abs/2305.01498" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Meta-review generation with checklist-guided iterative introspection</b></i>, Zeng et al., <a href="https://arxiv.org/abs/2305.14647" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>When Reviewers Lock Horn: Finding Disagreement in Scientific Peer Reviews</b></i>, Kumar et al., <a href="https://arxiv.org/abs/2310.18685" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>A sentiment consolidation framework for meta-review generation</b></i>, Li et al., <a href="https://arxiv.org/abs/2402.18005" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts</b></i>, Santu et al., <a href="https://arxiv.org/abs/2402.15589" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards automated meta-review generation via an NLP/ML pipeline in different stages of the scholarly peer review process</b></i>, Kumar et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Metawriter: Exploring the potential and perils of ai writing support in scientific peer review</b></i>, Sun et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>GLIMPSE: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews</b></i>, Darrin et al., <a href="https://arxiv.org/abs/2406.07359" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>PeerArg: Argumentative Peer Review with LLMs</b></i>, Sukpanichnant et al., <a href="https://arxiv.org/abs/2409.16813" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Bridging Social Psychology and LLM Reasoning: Conflict-Aware Meta-Review Generation via Cognitive Alignment</b></i>, Chen et al., <a href="https://arxiv.org/abs/2503.13879" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMs as Meta-Reviewers' Assistants: A Case Study</b></i>, Hossain et al., <a href="https://aclanthology.org/2025.naacl-long.395/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.04-blue" alt="PDF Badge"></a></li>
</ul>



<h3 id="post-review">5.3 Post-Review</h3>
<h4 id="influence-analysis">5.3.5 Influence Analysis</h4>
</ul>

<ul>
<li><i><b>Popular and/or prestigious? Measures of scholarly esteem</b></i>, Ding et al., <img src="https://img.shields.io/badge/Information processing & management-2011-green" alt="Information processing & management Badge"></li>
<li><i><b>Measuring academic influence: Not all citations are equal</b></i>, Zhu et al., <img src="https://img.shields.io/badge/Other Source-2015.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>An overview of microsoft academic service (mas) and applications</b></i>, Sinha et al., <img src="https://img.shields.io/badge/Other Source-2015.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Factors affecting number of citations: a comprehensive review of the literature</b></i>, Tahamtan et al., <img src="https://img.shields.io/badge/Scientometrics-2016-green" alt="Scientometrics Badge"></li>
<li><i><b>Relative citation ratio (RCR): a new metric that uses citation rates to measure influence at the article level</b></i>, Hutchins et al., <img src="https://img.shields.io/badge/PLoS biology-2016-green" alt="PLoS biology Badge"></li>
<li><i><b>HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction</b></i>, Hao et al., <a href="https://arxiv.org/abs/2410.09112" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>From Words to Worth: Newborn Article Impact Prediction with LLM</b></i>, Zhao et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
<li><i><b>Large language models surpass human experts in predicting neuroscience results</b></i>, Luo et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
</ul>

<h4 id="promotion-enhancement">5.3.6 Promotion Enhancement</h4>
</ul>

<ul>
<li><i><b>From complexity to clarity: How AI enhances perceptions of scientists and the public's understanding of science</b></i>, Markowitz et al., <img src="https://img.shields.io/badge/PNAS nexus-2024-green" alt="PNAS nexus Badge"></li>
<li><i><b>Automatic Evaluation Metrics for Artificially Generated Scientific Research</b></i>, H{\"o}pner et al., <a href="https://arxiv.org/abs/2503.05712" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation</b></i>, Park et al., <a href="https://arxiv.org/abs/2504.18805" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark</b></i>, Sun et al., <a href="https://arxiv.org/abs/2505.17104" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

</ul>

<ul>
<li><i><b>Can we automate scientific reviewing?</b></i>, Yuan et al., <img src="https://img.shields.io/badge/Other Source-2022.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Reviewergpt? an exploratory study on using large language models for paper reviewing</b></i>, Liu et al., <a href="https://arxiv.org/abs/2306.00622" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Unveiling the sentinels: Assessing ai performance in cybersecurity peer review</b></i>, Niu et al., <a href="https://arxiv.org/abs/2309.05457" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated scholarly paper review: Concepts, technologies, and challenges</b></i>, Lin et al., <img src="https://img.shields.io/badge/Information fusion-2023-green" alt="Information fusion Badge"></li>
<li><i><b>What Can Natural Language Processing Do for Peer Review?</b></i>, Kuznetsov et al., <a href="https://arxiv.org/abs/2405.06563" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence to support publishing and peer review: A summary and review</b></i>, Kousha et al., <img src="https://img.shields.io/badge/Learned Publishing-2024-green" alt="Learned Publishing Badge"></li>
<li><i><b>Large language models for automated scholarly paper review: A survey</b></i>, Zhuang et al., <a href="https://arxiv.org/abs/2501.10326" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Evaluating the predictive capacity of ChatGPT for academic peer review outcomes across multiple platforms</b></i>, Thelwall et al., <img src="https://img.shields.io/badge/Scientometrics-2025-green" alt="Scientometrics Badge"></li>
<li><i><b>A framework for reviewing the results of automated conversion of structured organic synthesis procedures from the literature</b></i>, Machi et al., <img src="https://img.shields.io/badge/Digital Discovery-2025-green" alt="Digital Discovery Badge"></li>
</ul>
<h2 id="application">6. Application</h2>


<h3 id="ai-for-natural-science-research">6.1 AI for Natural Science Research</h3>
<img src="./assets/images/application.png" style="width: 580pt">
<h4 id="ai-for-physics-research">6.1.1 AI for Physics Research</h4>
<b>Physical World Simulation</b>
<ul>
<li><i><b>Interaction networks for learning about objects, relations and physics</b></i>, Battaglia et al., <img src="https://img.shields.io/badge/NeurIPS-2016-green" alt="NeurIPS Badge"></li>
<li><i><b>End-to-end differentiable physics for learning and control</b></i>, de Avila Belbute-Peres et al., <img src="https://img.shields.io/badge/NeurIPS-2018-green" alt="NeurIPS Badge"></li>
<li><i><b>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</b></i>, Raissi et al., <img src="https://img.shields.io/badge/Journal of Computational physics-2019-green" alt="Journal of Computational physics Badge"></li>
<li><i><b>Hamiltonian neural networks</b></i>, Greydanus et al., <img src="https://img.shields.io/badge/NeurIPS-2019-green" alt="NeurIPS Badge"></li>
<li><i><b>Lagrangian neural networks</b></i>, Cranmer et al., <a href="https://arxiv.org/abs/2003.04630" target="_blank"><img src="https://img.shields.io/badge/arXiv-2020.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Physics-informed neural networks and extensions</b></i>, Raissi et al., <a href="https://arxiv.org/abs/2408.16806" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
</ul>

<b>Automated Law Discovery</b>
<ul>
<li><i><b>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models</b></i>, Shojaee et al., <a href="https://openreview.net/forum?id=m2nmp8P5in" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.01-blue" alt="PDF Badge"></a></li>
<li><i><b>LLM-Feynman: Leveraging Large Language Models for Universal Scientific Formula and Theory Discovery</b></i>, Song et al., <a href="https://arxiv.org/abs/2503.06512" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Newton: A Concept-Driven Physical Law Discovery System without Prior Physical Knowledge</b></i>, Fang et al., <a href="https://arxiv.org/abs/2504.01538" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>MLLM-based Discovery of Intrinsic Coordinates and Governing Equations from High-Dimensional Data</b></i>, Li et al., <a href="https://arxiv.org/abs/2505.11940" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models</b></i>, Shojaee et al., <a href="https://openreview.net/forum?id=SyQPiZJVWY" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience</b></i>, Wang et al., <a href="https://arxiv.org/abs/2506.04282" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Colloquium: Machine learning in nuclear physics</b></i>, Boehnlein et al., <img src="https://img.shields.io/badge/Reviews of modern physics-2022-green" alt="Reviews of modern physics Badge"></li>
<li><i><b>Toward the end-to-end optimization of particle physics instruments with differentiable programming</b></i>, Dorigo et al., <img src="https://img.shields.io/badge/Reviews in Physics-2023-green" alt="Reviews in Physics Badge"></li>
<li><i><b>AI meets physics: a comprehensive survey</b></i>, Jiao et al., <img src="https://img.shields.io/badge/Artificial Intelligence Review-2024-green" alt="Artificial Intelligence Review Badge"></li>
<li><i><b>Artificial intelligence for partial differential equations in computational mechanics: A review</b></i>, Wang et al., <a href="https://arxiv.org/abs/2410.19843" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>When physics meets machine learning: A survey of physics-informed machine learning</b></i>, Meng et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
</ul>

<h4 id="ai-for-biology-medical-research">6.1.2 AI for Biology & Medical Research</h4>
</ul>

<b>Protein Discovery.</b>
<ul>
<li><i><b>Improved protein structure prediction using potentials from deep learning</b></i>, Senior et al., <img src="https://img.shields.io/badge/Nature-2020-green" alt="Nature Badge"></li>
<li><i><b>Highly accurate protein structure prediction with AlphaFold</b></i>, Jumper et al., <img src="https://img.shields.io/badge/nature-2021-green" alt="nature Badge"></li>
<li><i><b>Leveraging biomolecule and natural language through multi-modal learning: A survey</b></i>, Pei et al., <a href="https://arxiv.org/abs/2403.01528" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>ProtAgents: protein discovery via large language model multi-agent collaborations combining physics and machine learning</b></i>, Ghafarollahi et al., <img src="https://img.shields.io/badge/Digital Discovery-2024-green" alt="Digital Discovery Badge"></li>
<li><i><b>Accurate structure prediction of biomolecular interactions with AlphaFold 3</b></i>, Abramson et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Automating exploratory proteomics research via language models</b></i>, Ding et al., <a href="https://arxiv.org/abs/2411.03743" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles</b></i>, Ghafarollahi et al., <a href="https://arxiv.org/abs/2504.19017" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning</b></i>, Lin et al., <a href="https://arxiv.org/abs/2505.02639" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Cell & Gene Modeling.</b>
<ul>
<li><i><b>GenePT: a simple but effective foundation model for genes and cells built from ChatGPT</b></i>, Chen et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>Biodiscoveryagent: An ai agent for designing genetic perturbation experiments</b></i>, Roohani et al., <a href="https://arxiv.org/abs/2405.17631" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Cellagent: An llm-driven multi-agent framework for automated single-cell data analysis</b></i>, Xiao et al., <a href="https://arxiv.org/abs/2407.09811" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Toward a foundation model of causal cell and tissue biology with a Perturbation Cell and Tissue Atlas</b></i>, Rood et al., <img src="https://img.shields.io/badge/Cell-2024-green" alt="Cell Badge"></li>
<li><i><b>General-purpose pre-trained large cellular models for single-cell transcriptomics</b></i>, Bian et al., <img src="https://img.shields.io/badge/National Science Review-2024-green" alt="National Science Review Badge"></li>
<li><i><b>ML-GAP: machine learning-enhanced genomic analysis pipeline using autoencoders and data augmentation</b></i>, Agraz et al., <img src="https://img.shields.io/badge/Frontiers in Genetics-2024-green" alt="Frontiers in Genetics Badge"></li>
<li><i><b>LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs--Evaluation through Synthetic Data Generation</b></i>, Afonja et al., <a href="https://arxiv.org/abs/2410.15828" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Autonomous Robotic System with Optical Coherence Tomography Guidance for Vascular Anastomosis</b></i>, Haworth et al., <a href="https://arxiv.org/abs/2410.07493" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>How to build the virtual cell with artificial intelligence: Priorities and opportunities</b></i>, Bunne et al., <img src="https://img.shields.io/badge/Cell-2024-green" alt="Cell Badge"></li>
<li><i><b>Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot Molecular Perturbation Prediction</b></i>, Maleki et al., <a href="https://arxiv.org/abs/2412.13478" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>NeuroDISK: An AI Approach to Automate Continuous Inquiry-Driven Discoveries in Neuroimaging Genetics</b></i>, Garijo et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>The rise of agentic AI teammates in medicine</b></i>, Zou et al., <img src="https://img.shields.io/badge/The Lancet-2025-green" alt="The Lancet Badge"></li>
<li><i><b>Transformers and genome language models</b></i>, Consens et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
</ul>

<b>Drug Discovery</b>
<ul>
<li><i><b>A deep learning approach to antibiotic discovery</b></i>, Stokes et al., <img src="https://img.shields.io/badge/Cell-2020-green" alt="Cell Badge"></li>
<li><i><b>Artificial intelligence to deep learning: machine intelligence approach for drug discovery</b></i>, Gupta et al., <img src="https://img.shields.io/badge/Molecular diversity-2021-green" alt="Molecular diversity Badge"></li>
<li><i><b>HGTDR: Advancing drug repurposing with heterogeneous graph transformers</b></i>, Gharizadeh et al., <img src="https://img.shields.io/badge/Bioinformatics-2024-green" alt="Bioinformatics Badge"></li>
<li><i><b>A survey of generative AI for de novo drug design: new frontiers in molecule and protein generation</b></i>, Tang et al., <img src="https://img.shields.io/badge/Briefings in Bioinformatics-2024-green" alt="Briefings in Bioinformatics Badge"></li>
<li><i><b>A data science roadmap for open science organizations engaged in early-stage drug discovery</b></i>, Edfeldt et al., <img src="https://img.shields.io/badge/Nature Communications-2024-green" alt="Nature Communications Badge"></li>
<li><i><b>Drugclip: Contrastive drug-disease interaction for drug repurposing</b></i>, Lu et al., <a href="https://arxiv.org/abs/2407.02265" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Current strategies to address data scarcity in artificial intelligence-based drug discovery: A comprehensive review</b></i>, Gangwal et al., <img src="https://img.shields.io/badge/Other Source-2024.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A foundation model for clinician-centered drug repurposing</b></i>, Huang et al., <img src="https://img.shields.io/badge/Nature Medicine-2024-green" alt="Nature Medicine Badge"></li>
<li><i><b>Drugagent: Automating ai-aided drug discovery programming through llm multi-agent collaboration</b></i>, Liu et al., <a href="https://arxiv.org/abs/2411.15692" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards LLM-Driven Multi-Agent Pipeline for Drug Discovery: Neurodegenerative Diseases Case Study</b></i>, Solovev et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data</b></i>, Lee et al., <a href="https://arxiv.org/abs/2412.20373" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Hallucinations Can Improve Large Language Models in Drug Discovery</b></i>, Yuan et al., <a href="https://arxiv.org/abs/2501.13824" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>RAG-Enhanced Collaborative LLM Agents for Drug Discovery</b></i>, Lee et al., <a href="https://arxiv.org/abs/2502.17506" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>LUMI-lab: a Foundation Model-Driven Autonomous Platform Enabling Discovery of New Ionizable Lipid Designs for mRNA Delivery</b></i>, Cui et al., <img src="https://img.shields.io/badge/BioRxiv-2025-green" alt="BioRxiv Badge"></li>
<li><i><b>Advancing drug discovery and development through GPT models: a review on challenges, innovations and future prospects</b></i>, Othman et al., <img src="https://img.shields.io/badge/Intelligence-Based Medicine-2025-green" alt="Intelligence-Based Medicine Badge"></li>
<li><i><b>DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery</b></i>, Li et al., <a href="https://arxiv.org/abs/2505.13940" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-assisted Drug Re-purposing for Human Liver Fibrosis</b></i>, Guan et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
</ul>

<b>Clinical Diagnosis</b>
<ul>
<li><i><b>Large language models encode clinical knowledge</b></i>, Singhal et al., <a href="https://doi.org/10.1038/s41586-023-06291-2" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis</b></i>, Wu et al., <a href="https://arxiv.org/abs/2310.09909" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Advancing clinical decision support: The role of artificial intelligence across six domains</b></i>, Khalifa et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Ai hospital: Benchmarking large language models in a multi-agent medical interaction simulator</b></i>, Fan et al., <a href="https://arxiv.org/abs/2402.09742" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Agent hospital: A simulacrum of hospital with evolvable medical agents</b></i>, Li et al., <a href="https://arxiv.org/abs/2405.02957" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Autonomous Robotic System with Optical Coherence Tomography Guidance for Vascular Anastomosis</b></i>, Haworth et al., <a href="https://arxiv.org/abs/2410.07493" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Piors: Personalized intelligent outpatient reception based on large language model with multi-agents medical scenario simulation</b></i>, Bao et al., <a href="https://arxiv.org/abs/2411.13902" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards an AI co-scientist</b></i>, Gottweis et al., <a href="https://arxiv.org/abs/2502.18864" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Generative Artificial Intelligence in Anatomic Pathology</b></i>, Brodsky et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Clinicalgpt-r1: Pushing reasoning capability of generalist disease diagnosis with large language model</b></i>, Lan et al., <a href="https://arxiv.org/abs/2504.09421" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework for Scientific Discovery</b></i>, Craig et al., <a href="https://aclanthology.org/2025.aisd-main.3/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient Interactions</b></i>, Kyung et al., <a href="https://arxiv.org/abs/2505.17818" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>MedSyn: Enhancing Diagnostics with Human-AI Collaboration</b></i>, Sayin et al., <a href="https://arxiv.org/abs/2506.14774" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis</b></i>, Wu et al., <a href="https://arxiv.org/abs/2310.09909" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Advancing multimodal medical capabilities of Gemini</b></i>, Yang et al., <a href="https://arxiv.org/abs/2405.03162" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of generative AI for de novo drug design: new frontiers in molecule and protein generation</b></i>, Tang et al., <img src="https://img.shields.io/badge/Briefings in Bioinformatics-2024-green" alt="Briefings in Bioinformatics Badge"></li>
<li><i><b>Large language models in plant biology</b></i>, Lam et al., <img src="https://img.shields.io/badge/Trends in Plant Science-2024-green" alt="Trends in Plant Science Badge"></li>
<li><i><b>The virtual lab: AI agents design new SARS-CoV-2 nanobodies with experimental validation</b></i>, Swanson et al., <img src="https://img.shields.io/badge/bioRxiv-2024-green" alt="bioRxiv Badge"></li>
<li><i><b>A Fuzzy Logic-Based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy</b></i>, Jiang et al., <img src="https://img.shields.io/badge/Other Source-2025.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Human-AI Teaming Using Large Language Models: Boosting Brain-Computer Interfacing (BCI) and Brain Research</b></i>, Kapitonova et al., <a href="https://arxiv.org/abs/2501.01451" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine</b></i>, Buess et al., <a href="https://arxiv.org/abs/2502.09242" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of llm-based agents in medicine: How far are we from baymax?</b></i>, Wang et al., <a href="https://arxiv.org/abs/2502.11211" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language model for knowledge synthesis and AI-enhanced biomanufacturing</b></i>, Li et al., <img src="https://img.shields.io/badge/Trends in Biotechnology-2025-green" alt="Trends in Biotechnology Badge"></li>
<li><i><b>Advancing drug discovery and development through GPT models: a review on challenges, innovations and future prospects</b></i>, Othman et al., <img src="https://img.shields.io/badge/Intelligence-Based Medicine-2025-green" alt="Intelligence-Based Medicine Badge"></li>
<li><i><b>Large Language Models for Zero-shot Inference of Causal Structures in Biology</b></i>, Newsham et al., <a href="https://arxiv.org/abs/2503.04347" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Transforming hematological research documentation with large language models: an approach to scientific writing and data analysis</b></i>, Yang et al., <img src="https://img.shields.io/badge/Blood research-2025-green" alt="Blood research Badge"></li>
<li><i><b>SpatialAgent: An autonomous AI agent for spatial biology</b></i>, Wang et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>A Human-LLM Note-Taking System with Case-Based Reasoning as Framework for Scientific Discovery</b></i>, Craig et al., <a href="https://aclanthology.org/2025.aisd-main.3/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>AI-assisted Drug Re-purposing for Human Liver Fibrosis</b></i>, Guan et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>Biomni: A General-Purpose Biomedical AI Agent</b></i>, Huang et al., <img src="https://img.shields.io/badge/bioRxiv-2025-green" alt="bioRxiv Badge"></li>
<li><i><b>Autonomous LLM-Driven Research—from Data to Human-Verifiable Research Papers</b></i>, Ifargan et al., <img src="https://img.shields.io/badge/NEJM AI-2025-green" alt="NEJM AI Badge"></li>
</ul>

<h4 id="ai-for-chemistry&-materials-research">6.1.3 AI for Chemistry& Materials Research</h4>
</ul>

<b>Automatic Analysis</b>
<ul>
<li><i><b>Graph networks as a universal machine learning framework for molecules and crystals</b></i>, Chen et al., <img src="https://img.shields.io/badge/Chemistry of Materials-2019-green" alt="Chemistry of Materials Badge"></li>
<li><i><b>An autonomous laboratory for the accelerated synthesis of novel materials</b></i>, Szymanski et al., <img src="https://img.shields.io/badge/Nature-2023-green" alt="Nature Badge"></li>
<li><i><b>Accelerating the Discovery of Abiotic Vesicles with AI-Guided Automated Experimentation</b></i>, Ekosso et al., <img src="https://img.shields.io/badge/Langmuir-2024-green" alt="Langmuir Badge"></li>
<li><i><b>Sequential closed-loop Bayesian optimization as a guide for organic molecular metallophotocatalyst formulation discovery</b></i>, Li et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>High-throughput robotic collection, imaging, and machine learning analysis of salt patterns: composition and concentration from dried droplet photos</b></i>, Batista et al., <img src="https://img.shields.io/badge/Digital Discovery-2025-green" alt="Digital Discovery Badge"></li>
<li><i><b>Adaptive representation of molecules and materials in Bayesian optimization</b></i>, Rajabi-Kochi et al., <img src="https://img.shields.io/badge/Chemical Science-2025-green" alt="Chemical Science Badge"></li>
<li><i><b>FlavorDiffusion: Modeling Food-Chemical Interactions with Diffusion</b></i>, Seo et al., <a href="https://aclanthology.org/2025.aisd-main.7/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
</ul>

<b>Automatic Discovery</b>
<ul>
<li><i><b>Chatgpt-Assisted Rational Design for Iterative Performance Optimization of Perovskite Solar Cells</b></i>, Zhang et al., <img src="https://img.shields.io/badge/Available at SSRN 5127472--green" alt="Available at SSRN 5127472 Badge"></li>
<li><i><b>Machine learning for molecular and materials science</b></i>, Butler et al., <img src="https://img.shields.io/badge/Nature-2018-green" alt="Nature Badge"></li>
<li><i><b>Scaling deep learning for materials discovery</b></i>, Merchant et al., <img src="https://img.shields.io/badge/Nature-2023-green" alt="Nature Badge"></li>
<li><i><b>Experimental discovery of novel ammonia synthesis catalysts via active learning</b></i>, Jayarathna et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A sober look at LLMs for material discovery: Are they actually good for Bayesian optimization over molecules?</b></i>, Kristiadi et al., <a href="https://arxiv.org/abs/2402.05015" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>BatGPT-Chem: A Foundation Large Model For Chemical Engineering</b></i>, Yang et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>AI-assisted inverse design of sequence-ordered high intrinsic thermal conductivity polymers</b></i>, Huang et al., <img src="https://img.shields.io/badge/Materials Today Physics-2024-green" alt="Materials Today Physics Badge"></li>
<li><i><b>Real-time experiment-theory closed-loop interaction for autonomous materials science</b></i>, Liang et al., <a href="https://arxiv.org/abs/2410.17430" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Autonomous mobile robots for exploratory synthetic chemistry</b></i>, Dai et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Machine Learning-Aided Inverse Design and Discovery of Novel Polymeric Materials for Membrane Separation</b></i>, Dangayach et al., <img src="https://img.shields.io/badge/Environmental Science & Technology-2024-green" alt="Environmental Science & Technology Badge"></li>
<li><i><b>ORGANA: a robotic assistant for automated chemistry experimentation and characterization</b></i>, Darvish et al., <img src="https://img.shields.io/badge/Matter-2025-green" alt="Matter Badge"></li>
<li><i><b>Adaptive AI decision interface for autonomous electronic material discovery</b></i>, Dai et al., <a href="https://arxiv.org/abs/2504.13344" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<b>Full Human-AI Collaboration Process Management</b>
<ul>
<li><i><b>Automated synthesis of oxygen-producing catalysts from Martian meteorites by a robotic AI chemist</b></i>, Zhu et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>ChemReasoner: Heuristic search over a large language model's knowledge space using quantum-chemical feedback</b></i>, Sprueill et al., <a href="https://arxiv.org/abs/2402.10980" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Efficient evolutionary search over chemical space with large language models</b></i>, Wang et al., <a href="https://arxiv.org/abs/2406.16976" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration</b></i>, Ni et al., <a href="https://arxiv.org/abs/2411.08063" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Autonomous Microscopy Experiments through Large Language Model Agents</b></i>, Mandal et al., <a href="https://arxiv.org/abs/2501.10385" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Automated Retrosynthesis Planning of Macromolecules Using Large Language Models and Knowledge Graphs</b></i>, Ma et al., <img src="https://img.shields.io/badge/Macromolecular Rapid Communications-2025-green" alt="Macromolecular Rapid Communications Badge"></li>
<li><i><b>A multiagent-driven robotic ai chemist enabling autonomous chemical research on demand</b></i>, Song et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agentic Assistant for Material Scientists</b></i>, Feng et al., <img src="https://img.shields.io/badge/Other Source-2025.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Physics-informed, dual-objective optimization of high-entropy-alloy nanozymes by a robotic AI chemist</b></i>, Luo et al., <img src="https://img.shields.io/badge/Matter-2025-green" alt="Matter Badge"></li>
<li><i><b>Intelligent, Personalized Scientific Assistant via Large Language Models for Solid-State Battery Research</b></i>, Leng et al., <img src="https://img.shields.io/badge/ACS Materials Letters-2025-green" alt="ACS Materials Letters Badge"></li>
<li><i><b>Prim: Principle-inspired material discovery through multi-agent collaboration</b></i>, Lai et al., <a href="https://arxiv.org/abs/2504.08810" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>Accelerating materials discovery using artificial intelligence, high performance computing and robotics</b></i>, Pyzer-Knapp et al., <img src="https://img.shields.io/badge/npj Computational Materials-2022-green" alt="npj Computational Materials Badge"></li>
<li><i><b>Accelerating materials language processing with large language models</b></i>, Choi et al., <img src="https://img.shields.io/badge/Communications Materials-2024-green" alt="Communications Materials Badge"></li>
<li><i><b>Augmenting large language models with chemistry tools</b></i>, M. Bran et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Nano & AI: A Nobel Partnership</b></i>, Chen et al., <img src="https://img.shields.io/badge/ACS nano-2024-green" alt="ACS nano Badge"></li>
<li><i><b>Simulating 500 million years of evolution with a language model</b></i>, Hayes et al., <img src="https://img.shields.io/badge/Science-2025-green" alt="Science Badge"></li>
<li><i><b>AI4Materials: Transforming the Landscape of Materials Science and Enigneering</b></i>, Jiang et al., <img src="https://img.shields.io/badge/Review of Materials Research-2025-green" alt="Review of Materials Research Badge"></li>
<li><i><b>Cross-disciplinary perspectives on the potential for artificial intelligence across chemistry</b></i>, Mroz et al., <img src="https://img.shields.io/badge/Chemical Society Reviews-2025-green" alt="Chemical Society Reviews Badge"></li>
<li><i><b>Empowering Generalist Material Intelligence with Large Language Models</b></i>, Yuan et al., <img src="https://img.shields.io/badge/Advanced Materials-2025-green" alt="Advanced Materials Badge"></li>
<li><i><b>From Literature to Lab: Hardware-Independent Autonomous Chemical Synthesis with Reinforcement Learning</b></i>, Wu et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
</ul>



<h3 id="ai-for-applied-science-and-engineering-research">6.2 AI for Applied Science and Engineering Research</h3>
<h4 id="ai-for-robotics-and-control-research">6.2.4 AI for Robotics and Control Research</h4>
</ul>

<b>Autonomous Design & Optimization</b>
<ul>
<li><i><b>Towards industry-ready additive manufacturing: AI-enabled closed-loop control for 3D melt electrowriting</b></i>, Mieszczanek et al., <img src="https://img.shields.io/badge/Communications Engineering-2024-green" alt="Communications Engineering Badge"></li>
<li><i><b>Closed-loop transfer enables artificial intelligence to yield chemical knowledge</b></i>, Angello et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>Closed-Loop Visuomotor Control with Generative Expectation for Robotic Manipulation</b></i>, Bu et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Real-time experiment-theory closed-loop interaction for autonomous materials science</b></i>, Liang et al., <a href="https://arxiv.org/abs/2410.17430" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Driven Robotics for Free-Space Optics</b></i>, Uddin et al., <a href="https://arxiv.org/abs/2505.17985" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>End-to-End Vision-Based Control</b>
<ul>
<li><i><b>End-to-end training of deep visuomotor policies</b></i>, Levine et al., <img src="https://img.shields.io/badge/Other Source-2016.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Domain randomization for transferring deep neural networks from simulation to the real world</b></i>, Tobin et al., <img src="https://img.shields.io/badge/Other Source-2017.00-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection</b></i>, Levine et al., <img src="https://img.shields.io/badge/Other Source-2018.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Scalable deep reinforcement learning for vision-based robotic manipulation</b></i>, Kalashnikov et al., <img src="https://img.shields.io/badge/Other Source-2018.10-lightgrey" alt="Other Source Badge"></li>
</ul>

<b>Sim-to-Real Robustness & Safety</b>
<ul>
<li><i><b>Real-world humanoid locomotion with reinforcement learning</b></i>, Radosavovic et al., <img src="https://img.shields.io/badge/Science Robotics-2024-green" alt="Science Robotics Badge"></li>
<li><i><b>Improving generalization of robot locomotion policies via Sharpness-Aware Reinforcement Learning</b></i>, Bochem et al., <a href="https://arxiv.org/abs/2411.19732" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Robustness Evaluation of Offline Reinforcement Learning for Robot Control Against Action Perturbations</b></i>, Ayabe et al., <a href="https://arxiv.org/abs/2412.18781" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Zero-shot Sim-to-Real Transfer for Reinforcement Learning-based Visual Servoing of Soft Continuum Arms</b></i>, Yang et al., <a href="https://arxiv.org/abs/2504.16916" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning</b></i>, Guerrier et al., <a href="https://arxiv.org/abs/2505.18858" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Multi-Task & Multi-Agent Control Frameworks</b>
<ul>
<li><i><b>Value Iteration for Learning Concurrently Executable Robotic Control Tasks</b></i>, Tahmid et al., <a href="https://arxiv.org/abs/2504.01174" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>NovelSeek: When Agent Becomes the Scientist--Building Closed-Loop System from Hypothesis to Verification</b></i>, Team et al., <a href="https://arxiv.org/abs/2505.16938" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>The AI CUDA engineer: Agentic CUDA kernel discovery, optimization and composition</b></i>, Lange et al., <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review</b></i>, Lee et al., <a href="https://arxiv.org/abs/2505.00210" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="ai-for-software-engineering">6.2.5 AI for Software Engineering</h4>
</ul>

<b>Code Generation</b>
<ul>
<li><i><b>Evaluating large language models trained on code</b></i>, Chen et al., <a href="https://arxiv.org/abs/2107.03374" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Codegen: An open large language model for code with multi-turn program synthesis</b></i>, Nijkamp et al., <a href="https://arxiv.org/abs/2203.13474" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Starcoder: may the source be with you!</b></i>, Li et al., <a href="https://arxiv.org/abs/2305.06161" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Code llama: Open foundation models for code</b></i>, Roziere et al., <a href="https://arxiv.org/abs/2308.12950" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.08-red" alt="arXiv Badge"></a></li>
<li><i><b>DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence</b></i>, Guo et al., <a href="https://arxiv.org/abs/2401.14196" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Starcoder 2 and the stack v2: The next generation</b></i>, Lozhkov et al., <a href="https://arxiv.org/abs/2402.19173" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios</b></i>, Huang et al., <a href="https://arxiv.org/abs/2506.13824" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Seed-Coder: Let the Code Model Curate Data for Itself</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2506.03524" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>End-to-End Software Development</b>
<ul>
<li><i><b>Application of large language models to software engineering tasks: Opportunities, risks, and implications</b></i>, Ozkaya et al., <img src="https://img.shields.io/badge/IEEE Software-2023-green" alt="IEEE Software Badge"></li>
<li><i><b>Chatdev: Communicative agents for software development</b></i>, Qian et al., <a href="https://arxiv.org/abs/2307.07924" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models for software engineering: Survey and open problems</b></i>, Fan et al., <img src="https://img.shields.io/badge/Other Source-2023.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Experiential co-learning of software-developing agents</b></i>, Qian et al., <a href="https://arxiv.org/abs/2312.17025" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Repoexec: Evaluate code generation with a repository-level executable benchmark</b></i>, Le Hai et al., <img src="https://img.shields.io/badge/arXiv e-prints-2024-green" alt="arXiv e-prints Badge"></li>
<li><i><b>SWE-bench: Can Language Models Resolve Real-world Github Issues?</b></i>, Jimenez et al., <a href="https://openreview.net/forum?id=VTF8yNQM66" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.01-blue" alt="PDF Badge"></a></li>
<li><i><b>Hyperagent: Generalist software engineering agents to solve coding tasks at scale</b></i>, Phan et al., <a href="https://arxiv.org/abs/2409.16299" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Explainable automated debugging via large language model-driven scientific debugging</b></i>, Kang et al., <img src="https://img.shields.io/badge/Empirical Software Engineering-2025-green" alt="Empirical Software Engineering Badge"></li>
</ul>



<h3 id="ai-for-social-science-research">6.3 AI for Social Science Research</h3>
<h4 id="ai-for-sociology-research">6.3.6 AI for Sociology Research</h4>
</ul>

<b>AI-Assisted Experimental and Interview Studies.</b>
<ul>
<li><i><b>Automated social science: Language models as scientist and subjects</b></i>, Manning et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Step Further Towards Automated Social Science: An AI-Powered Interview Platform</b></i>, Liu et al., <img src="https://img.shields.io/badge/Available at SSRN-2024-green" alt="Available at SSRN Badge"></li>
</ul>

<b>Large-Scale Simulation of Social Phenomena.</b>
<ul>
<li><i><b>RAISE: A New Method to Develop Experimental Stimuli for Advertising Research with Image Generative Artificial Intelligence</b></i>, Zamudio et al., <img src="https://img.shields.io/badge/Journal of Advertising-2024-green" alt="Journal of Advertising Badge"></li>
<li><i><b>Cultural evolution in populations of Large Language Models</b></i>, Perez et al., <a href="https://arxiv.org/abs/2403.08882" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Economic Anthropology in the Era of Generative Artificial Intelligence</b></i>, Sheldon et al., <a href="https://arxiv.org/abs/2410.15238" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Malinowski in the Age of AI: Can large language models create a text game based on an anthropological classic?</b></i>, Hoffmann et al., <a href="https://arxiv.org/abs/2410.20536" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making</b></i>, Huang et al., <a href="https://arxiv.org/abs/2411.03865" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>ResearchTown: Simulator of Human Research Community</b></i>, Yu et al., <a href="https://arxiv.org/abs/2412.17767" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Simulating cooperative prosocial behavior with multi-agent LLMs: Evidence and mechanisms for AI agents to inform policy decisions</b></i>, Sreedhar et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Predicting Field Experiments with Large Language Models</b></i>, Chen et al., <a href="https://arxiv.org/abs/2504.01167" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Language Models Surface the Unwritten Code of Science and Society</b></i>, Bao et al., <a href="https://arxiv.org/abs/2505.18942" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Potential Risks Discussion.</b>
<ul>
<li><i><b>Automated social science: Language models as scientist and subjects</b></i>, Manning et al., <img src="https://img.shields.io/badge/Other Source-2024.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>ChatGPT as research scientist: probing GPT’s capabilities as a research librarian, research ethicist, data generator, and data predictor</b></i>, Lehr et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Predicting Results of Social Science Experiments Using Large Language Models</b></i>, Luke et al., <a href="https://samim.io/dl/Predicting%20results%20of%20social%20science%20experiments%20using%20large%20language%20models.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
</ul>

<ul>
<li><i><b>Ethnography and Machine Learning: Synergies and New Directions</b></i>, Li et al., <a href="https://arxiv.org/abs/2412.06087" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Machine-assisted quantitizing designs: augmenting humanities and social sciences with artificial intelligence</b></i>, Karjus et al., <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agent-Enhanced Large Language Models for Researching Political Institutions</b></i>, Loffredo et al., <a href="https://arxiv.org/abs/2503.13524" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Reimagining urban science: Scaling causal inference with large language models</b></i>, Xia et al., <a href="https://arxiv.org/abs/2504.12345" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="ai-for-psychology-research">6.3.7 AI for Psychology Research</h4>
</ul>

<b>Experiment Workflow Automation and Simulation.</b>
<ul>
<li><i><b>Using cognitive psychology to understand GPT-3</b></i>, Binz et al., <a href="http://dx.doi.org/10.1073/pnas.2218523120" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.02-blue" alt="PDF Badge"></a></li>
<li><i><b>Can AI language models replace human participants?</b></i>, Dillion et al., <a href="https://www.sciencedirect.com/science/article/pii/S1364661323000980" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.07-blue" alt="PDF Badge"></a></li>
<li><i><b>The emergence of economic rationality of GPT</b></i>, Chen et al., <img src="https://img.shields.io/badge/Other Source-2023.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>AI-experiments in education: An AI-driven randomized controlled trial for higher education research</b></i>, Cingillioglu et al., <img src="https://img.shields.io/badge/Education and Information Technologies-2024-green" alt="Education and Information Technologies Badge"></li>
<li><i><b>RAISE: A New Method to Develop Experimental Stimuli for Advertising Research with Image Generative Artificial Intelligence</b></i>, Zamudio et al., <img src="https://img.shields.io/badge/Journal of Advertising-2024-green" alt="Journal of Advertising Badge"></li>
<li><i><b>Frontiers: Can Large Language Models Capture Human Preferences?</b></i>, Goli et al., <a href="https://doi.org/10.1287/mksc.2023.0306" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.04-blue" alt="PDF Badge"></a></li>
<li><i><b>Testing theory of mind in large language models and humans</b></i>, Strachan et al., <a href="https://www.nature.com/articles/s41562-024-01895-1" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.05-blue" alt="PDF Badge"></a></li>
<li><i><b>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.</b></i>, Suri et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Towards a client-centered assessment of llm therapists by client simulation</b></i>, Wang et al., <a href="https://arxiv.org/abs/2406.12266" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Interactive agents: Simulating counselor-client psychological counseling via role-playing llm-to-llm interactions</b></i>, Qiu et al., <a href="https://arxiv.org/abs/2408.15787" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Can AI Replace Human Subjects? A Large-Scale Replication of Psychological Experiments with LLMs</b></i>, Cui et al., <a href="https://arxiv.org/abs/2409.00128" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
</ul>

<b>Human-AI Trust and Safety Design.</b>
<ul>
<li><i><b>MMSD2. 0: Towards a reliable multi-modal sarcasm detection system</b></i>, Qin et al., <a href="https://arxiv.org/abs/2307.07135" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Developing trustworthy artificial intelligence: insights from research on interpersonal, human-automation, and human-AI trust</b></i>, Li et al., <img src="https://img.shields.io/badge/Frontiers in Psychology-2024-green" alt="Frontiers in Psychology Badge"></li>
<li><i><b>From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents</b></i>, Chandra et al., <a href="https://arxiv.org/abs/2412.07951" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
</ul>

<b>Psychological Interventions.</b>
<ul>
<li><i><b>Using cognitive psychology to understand GPT-3</b></i>, Binz et al., <a href="http://dx.doi.org/10.1073/pnas.2218523120" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.02-blue" alt="PDF Badge"></a></li>
<li><i><b>Can AI language models replace human participants?</b></i>, Dillion et al., <a href="https://www.sciencedirect.com/science/article/pii/S1364661323000980" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.07-blue" alt="PDF Badge"></a></li>
<li><i><b>Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT</b></i>, Hagendorff et al., <a href="http://dx.doi.org/10.1038/s43588-023-00527-x" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.10-blue" alt="PDF Badge"></a></li>
<li><i><b>Large Language Models Can Enable Inductive Thematic Analysis of a Social Media Corpus in a Single Prompt: Human Validation Study</b></i>, Deiner et al., <a href="https://doi.org/10.2196/59641" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Crafting clarity: Leveraging large language models to decode consumer reviews</b></i>, Praveen et al., <a href="https://www.sciencedirect.com/science/article/pii/S0969698924002716" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>ChatGPT for Textual Analysis? How to Use Generative LLMs in Accounting Research</b></i>, de Kok et al., <a href="https://doi.org/10.1287/mnsc.2023.03253" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.01-blue" alt="PDF Badge"></a></li>
<li><i><b>The use of artificial intelligence in psychotherapy: development of intelligent therapeutic systems</b></i>, Spytska et al., <img src="https://img.shields.io/badge/BMC psychology-2025-green" alt="BMC psychology Badge"></li>
<li><i><b>Randomized trial of a generative ai chatbot for mental health treatment</b></i>, Heinz et al., <img src="https://img.shields.io/badge/Nejm Ai-2025-green" alt="Nejm Ai Badge"></li>
<li><i><b>Large language models as mental health resources: Patterns of use in the united states</b></i>, Rousmaniere et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Large Language Models Pass the Turing Test</b></i>, Jones et al., <a href="https://arxiv.org/abs/2503.23674" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Experiential Narratives in Marketing: A Comparison of Generative AI and Human Content</b></i>, Wen et al., <a href="https://doi.org/10.1177/07439156241297973" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.10-blue" alt="PDF Badge"></a></li>
</ul>

<ul>
<li><i><b>Automating psychological hypothesis generation with AI: when large language models meet causal graph</b></i>, Tong et al., <img src="https://img.shields.io/badge/Other Source-2024.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits</b></i>, Li et al., <a href="https://arxiv.org/abs/2412.12510" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
</ul>
<h2 id="future-and-frontiers">7. Future and Frontiers</h2>

<img src="./assets/images/future.png" style="width: 580pt">



<h3 id="interdisciplinary-ai-models">7.1 Interdisciplinary AI Models</h3>
<ul>
<li><i><b>Artificial intelligence in cancer research: learning at different levels of data granularity</b></i>, Cirillo et al., <img src="https://img.shields.io/badge/Molecular oncology-2021-green" alt="Molecular oncology Badge"></li>
<li><i><b>Generating full length wikipedia biographies: The impact of gender bias on the retrieval-based generation of women biographies</b></i>, Fan et al., <a href="https://arxiv.org/abs/2204.05879" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Contrastive knowledge integrated graph neural networks for Chinese medical text classification</b></i>, Lan et al., <img src="https://img.shields.io/badge/Other Source-2023.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Heterogeneous federated learning: State-of-the-art and research challenges</b></i>, Ye et al., <img src="https://img.shields.io/badge/ACM Computing Surveys-2023-green" alt="ACM Computing Surveys Badge"></li>
<li><i><b>A comprehensive survey of cross-domain policy transfer for embodied agents</b></i>, Niu et al., <a href="https://arxiv.org/abs/2402.04580" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models</b></i>, Gu et al., <a href="https://arxiv.org/abs/2405.17044" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of trustworthy representation learning across domains</b></i>, Zhu et al., <img src="https://img.shields.io/badge/Other Source-2024.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science</b></i>, Lin et al., <a href="https://arxiv.org/abs/2407.00466" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Knowledge transfer for cross-domain reinforcement learning: a systematic review</b></i>, Serrano et al., <img src="https://img.shields.io/badge/IEEE Access-2024-green" alt="IEEE Access Badge"></li>
<li><i><b>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning</b></i>, Buehler et al., <img src="https://img.shields.io/badge/Other Source-2024.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Heterogeneous data integration: Challenges and opportunities</b></i>, Putrama et al., <img src="https://img.shields.io/badge/Data in Brief-2024-green" alt="Data in Brief Badge"></li>
<li><i><b>A comprehensive survey of foundation models in medicine</b></i>, Khan et al., <img src="https://img.shields.io/badge/Other Source-2025.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Foundation models and intelligent decision-making: Progress, challenges, and perspectives</b></i>, Huang et al., <img src="https://img.shields.io/badge/The Innovation-2025-green" alt="The Innovation Badge"></li>
</ul>



<h3 id="ethics-and-safety-in-ai4research">7.2 Ethics and Safety in AI4Research</h3>
</ul>

<ul>
<li><i><b>Causal learning for socially responsible AI</b></i>, Cheng et al., <a href="https://arxiv.org/abs/2104.12278" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence and ethics: a comprehensive review of bias mitigation, transparency, and accountability in AI Systems</b></i>, Mensah et al., <img src="https://img.shields.io/badge/Preprint, November-2023-green" alt="Preprint, November Badge"></li>
<li><i><b>Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies</b></i>, Ferrara et al., <img src="https://img.shields.io/badge/Sci-2023-green" alt="Sci Badge"></li>
<li><i><b>AXOLOTL: fairness through assisted self-debiasing of large language model outputs</b></i>, Ebrahimi et al., <a href="https://arxiv.org/abs/2403.00198" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Policy advice and best practices on bias and fairness in AI</b></i>, Alvarez et al., <img src="https://img.shields.io/badge/Ethics and Information Technology-2024-green" alt="Ethics and Information Technology Badge"></li>
<li><i><b>Automated Peer-Reviewer Assignment can be Manipulated to Secure Reviews from Colluders</b></i>, Hsieh et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Mitigating bias in artificial intelligence: Fair data generation via causal models for transparent and explainable decision-making</b></i>, Gonz{\'a}lez-Sendino et al., <img src="https://img.shields.io/badge/Future Generation Computer Systems-2024-green" alt="Future Generation Computer Systems Badge"></li>
<li><i><b>Enhancing peer review efficiency: A mixed-methods analysis of artificial intelligence-assisted reviewer selection across academic disciplines</b></i>, Farber et al., <img src="https://img.shields.io/badge/Learned Publishing-2024-green" alt="Learned Publishing Badge"></li>
<li><i><b>Beyond principlism: practical strategies for ethical AI use in research practices</b></i>, Lin et al., <img src="https://img.shields.io/badge/AI and Ethics-2024-green" alt="AI and Ethics Badge"></li>
<li><i><b>SciTrust: Evaluating the Trustworthiness of Large Language Models for Science</b></i>, Herron et al., <img src="https://img.shields.io/badge/Other Source-2024.11-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Are we there yet? revealing the risks of utilizing large language models in scholarly peer review</b></i>, Ye et al., <a href="https://arxiv.org/abs/2412.01708" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Vulnerability of Text-Matching in ML/AI Conference Reviewer Assignments to Collusions</b></i>, Raghunathan et al., <a href="https://arxiv.org/abs/2412.06606" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>How human--AI feedback loops alter human perceptual, emotional and social judgements</b></i>, Glickman et al., <img src="https://img.shields.io/badge/Nature-2025-green" alt="Nature Badge"></li>
<li><i><b>The hidden dimensions of llm alignment: A multi-dimensional safety analysis</b></i>, Pan et al., <a href="https://arxiv.org/abs/2502.09674" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Responsible AI in biotechnology: balancing discovery, innovation and biosecurity risks</b></i>, Wheeler et al., <img src="https://img.shields.io/badge/Other Source-2025.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>All that glitters is not novel: Plagiarism in ai generated research</b></i>, Gupta et al., <a href="https://arxiv.org/abs/2502.16487" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Detecting llm-written peer reviews</b></i>, Rao et al., <a href="https://arxiv.org/abs/2503.15772" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Ethical and bias considerations in artificial intelligence/machine learning</b></i>, Hanna et al., <img src="https://img.shields.io/badge/Modern Pathology-2025-green" alt="Modern Pathology Badge"></li>
<li><i><b>Automation Bias in AI-assisted Medical Decision-making under Time Pressure in Computational Pathology</b></i>, Rosbach et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Considering the Ethics of Large Machine Learning Models in the Chemical Sciences</b></i>, Spotte-Smith et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Generative artificial intelligence for academic research: evidence from guidance issued for researchers by higher education institutions in the United States</b></i>, Ganguly et al., <img src="https://img.shields.io/badge/AI and Ethics-2025-green" alt="AI and Ethics Badge"></li>
<li><i><b>Artificial intelligence and dichotomania</b></i>, McShane et al., <img src="https://img.shields.io/badge/Judgment and Decision Making-2025-green" alt="Judgment and Decision Making Badge"></li>
<li><i><b>The Plagiarism Singularity Conjecture</b></i>, Ranga et al., <img src="https://img.shields.io/badge/ACL-2025-green" alt="ACL Badge"></li>
<li><i><b>Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models</b></i>, Xiong et al., <a href="https://arxiv.org/abs/2505.14599" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>BiasFilter: An Inference-Time Debiasing Framework for Large Language Models</b></i>, Cheng et al., <a href="https://arxiv.org/abs/2505.23829" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2505.23559" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>OpenReview Should be Protected and Leveraged as a Community Asset for Research in the Era of Large Language Models</b></i>, Sun et al., <a href="https://arxiv.org/abs/2505.21537" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="ai-for-collaborative-research">7.3 AI for Collaborative Research</h3>
</ul>

<ul>
<li><i><b>A hybrid approach to privacy-preserving federated learning</b></i>, Truex et al., <img src="https://img.shields.io/badge/Other Source-2019.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A review of applications in federated learning</b></i>, Li et al., <img src="https://img.shields.io/badge/Computers & Industrial Engineering-2020-green" alt="Computers & Industrial Engineering Badge"></li>
<li><i><b>A survey on federated learning</b></i>, Zhang et al., <img src="https://img.shields.io/badge/Knowledge-Based Systems-2021-green" alt="Knowledge-Based Systems Badge"></li>
<li><i><b>A systematic review of federated learning: Challenges, aggregation methods, and development tools</b></i>, Guendouzi et al., <img src="https://img.shields.io/badge/Other Source-2023.11-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Federated learning and data privacy: A review of challenges and opportunities</b></i>, Myakala et al., <img src="https://img.shields.io/badge/Other Source-2024.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Designing collaborative intelligence systems for employee-AI service co-production</b></i>, Blaurock et al., <img src="https://img.shields.io/badge/Journal of Service Research-2024-green" alt="Journal of Service Research Badge"></li>
<li><i><b>Collaborative Intelligence: A scoping review of current applications</b></i>, Schleiger et al., <img src="https://img.shields.io/badge/Applied Artificial Intelligence-2024-green" alt="Applied Artificial Intelligence Badge"></li>
<li><i><b>Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation</b></i>, Holter et al., <img src="https://img.shields.io/badge/Other Source-2024.06-lightgrey" alt="Other Source Badge"></li>
<li><i><b>The ai scientist: Towards fully automated open-ended scientific discovery</b></i>, Lu et al., <a href="https://arxiv.org/abs/2408.06292" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Human-AI collaboration is not very collaborative yet: A taxonomy of interaction patterns in AI-assisted decision making from a systematic review</b></i>, Gomez et al., <img src="https://img.shields.io/badge/Frontiers in Computer Science-2025-green" alt="Frontiers in Computer Science Badge"></li>
<li><i><b>Text2world: Benchmarking large language models for symbolic world model generation</b></i>, Hu et al., <a href="https://arxiv.org/abs/2502.13092" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Distributed cross-learning for equitable federated models-privacy-preserving prediction on data from five California hospitals</b></i>, Kuo et al., <img src="https://img.shields.io/badge/Nature Communications-2025-green" alt="Nature Communications Badge"></li>
<li><i><b>Multi-agent risks from advanced ai</b></i>, Hammond et al., <a href="https://arxiv.org/abs/2502.14143" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Simulating cooperative prosocial behavior with multi-agent LLMs: Evidence and mechanisms for AI agents to inform policy decisions</b></i>, Sreedhar et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Accelerating drug discovery with Artificial: a whole-lab orchestration and scheduling system for self-driving labs</b></i>, Fehlis et al., <a href="https://arxiv.org/abs/2504.00986" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery</b></i>, Zimmermann et al., <a href="https://arxiv.org/abs/2505.03049" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery</b></i>, Li et al., <a href="https://arxiv.org/abs/2505.13940" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>The role of agentic ai in shaping a smart future: A systematic review</b></i>, Hosseini et al., <img src="https://img.shields.io/badge/Array-2025-green" alt="Array Badge"></li>
</ul>



<h3 id="explainability-and-transparency-of-ai4research">7.4 Explainability and Transparency of AI4Research</h3>
</ul>

<ul>
<li><i><b>On gradient-like explanation under a black-box setting: when black-box explanations become as good as white-box</b></i>, Cai et al., <a href="https://arxiv.org/abs/2308.09381" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Explainable and interpretable artificial intelligence in medicine: a systematic bibliometric review</b></i>, Frasca et al., <img src="https://img.shields.io/badge/Discover Artificial Intelligence-2024-green" alt="Discover Artificial Intelligence Badge"></li>
<li><i><b>Towards uncovering how large language model works: An explainability perspective</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2402.10688" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Mechanistic Interpretability for AI Safety--A Review</b></i>, Bereska et al., <a href="https://arxiv.org/abs/2404.14082" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>A practical review of mechanistic interpretability for transformer-based language models</b></i>, Rai et al., <a href="https://arxiv.org/abs/2407.02646" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Interpreting black-box models: a review on explainable artificial intelligence</b></i>, Hassija et al., <img src="https://img.shields.io/badge/Cognitive Computation-2024-green" alt="Cognitive Computation Badge"></li>
<li><i><b>Unlocking the capabilities of thought: A reasoning boundary framework to quantify and optimize chain-of-thought</b></i>, Chen et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Explainable AI reloaded: Challenging the xai status quo in the era of large language models</b></i>, Ehsan et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Beyond principlism: practical strategies for ethical AI use in research practices</b></i>, Lin et al., <img src="https://img.shields.io/badge/AI and Ethics-2024-green" alt="AI and Ethics Badge"></li>
<li><i><b>ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model</b></i>, Chen et al., <a href="https://arxiv.org/abs/2502.03325" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.13307" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="ai-for-dynamic-and-real‑time-optimized-scientific-experimentation">7.5 AI for Dynamic and Real‑Time Optimized Scientific Experimentation</h3>
</ul>

<ul>
<li><i><b>Tree-planner: Efficient close-loop task planning with large language models</b></i>, Hu et al., <a href="https://arxiv.org/abs/2310.08582" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Review of low-cost self-driving laboratories in chemistry and materials science: the “frugal twin” concept</b></i>, Lo et al., <img src="https://img.shields.io/badge/Digital Discovery-2024-green" alt="Digital Discovery Badge"></li>
<li><i><b>Self-driving laboratories for chemistry and materials science</b></i>, Tom et al., <img src="https://img.shields.io/badge/Chemical Reviews-2024-green" alt="Chemical Reviews Badge"></li>
<li><i><b>Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model</b></i>, Hu et al., <a href="https://arxiv.org/abs/2408.09559" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Real-time experiment-theory closed-loop interaction for autonomous materials science</b></i>, Liang et al., <a href="https://arxiv.org/abs/2410.17430" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoSciLab: A Self-Driving Laboratory For Interpretable Scientific Discovery</b></i>, Desai et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
<li><i><b>Adaptive AI decision interface for autonomous electronic material discovery</b></i>, Dai et al., <a href="https://arxiv.org/abs/2504.13344" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Science acceleration and accessibility with self-driving labs</b></i>, Canty et al., <img src="https://img.shields.io/badge/Nature Communications-2025-green" alt="Nature Communications Badge"></li>
</ul>



<h3 id="multimodal-integration-in-ai4research">7.6 Multimodal Integration in AI4Research</h3>
</ul>

<ul>
<li><i><b>Look, read and enrich-learning from scientific figures and their captions</b></i>, Gomez-Perez et al., <img src="https://img.shields.io/badge/Other Source-2019.09-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Uniter: Universal image-text representation learning</b></i>, Chen et al., <img src="https://img.shields.io/badge/ECCV-2020-green" alt="ECCV Badge"></li>
<li><i><b>T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering</b></i>, Wang et al., <a href="https://arxiv.org/abs/2305.03453" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Figcaps-hf: A figure-to-caption generative framework and benchmark with human feedback</b></i>, Singh et al., <a href="https://arxiv.org/abs/2307.10867" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>M <sup>3</sup> CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought</b></i>, Chen et al., <a href="https://arxiv.org/abs/2405.16473" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models</b></i>, Shi et al., <a href="https://arxiv.org/abs/2407.18626" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>S3 agent: Unlocking the power of VLLM for zero-shot multi-modal sarcasm detection</b></i>, Wang et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Vlm4bio: A benchmark dataset to evaluate pretrained vision-language models for trait discovery from biological images</b></i>, Maruf et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Model-in-the-Loop (MILO): Accelerating Multimodal AI Data Annotation with LLMs</b></i>, Wang et al., <a href="https://arxiv.org/abs/2409.10702" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>What factors affect multi-modal in-context learning? an in-depth exploration</b></i>, Qin et al., <a href="https://arxiv.org/abs/2410.20482" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Bigdocs: An open dataset for training multimodal models on document and code tasks</b></i>, Rodriguez et al., <img src="https://img.shields.io/badge/ICLR-2025-green" alt="ICLR Badge"></li>
<li><i><b>InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2502.15027" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>MERMaid: Universal multimodal mining of chemical reactions from PDFs using vision-language models</b></i>, Leong et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Comt: A novel benchmark for chain of multi-modal thought on large vision-language models</b></i>, Cheng et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
<li><i><b>Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought</b></i>, Cheng et al., <a href="https://arxiv.org/abs/2505.15510" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights</b></i>, Gokdemir et al., <a href="https://arxiv.org/abs/2505.04846" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="multilingual-integration-in-ai4research">7.7 Multilingual Integration in AI4Research</h3>
</ul>

<ul>
<li><i><b>Languages are still a major barrier to global science</b></i>, Amano et al., <img src="https://img.shields.io/badge/PLoS biology-2016-green" alt="PLoS biology Badge"></li>
<li><i><b>Unsupervised cross-lingual representation learning at scale</b></i>, Conneau et al., <a href="https://arxiv.org/abs/1911.02116" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.11-red" alt="arXiv Badge"></a></li>
<li><i><b>SimAlign: High quality word alignments without parallel training data using static and contextualized embeddings</b></i>, Sabet et al., <a href="https://arxiv.org/abs/2004.08728" target="_blank"><img src="https://img.shields.io/badge/arXiv-2020.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Ten tips for overcoming language barriers in science</b></i>, Amano et al., <img src="https://img.shields.io/badge/Nature-2021-green" alt="Nature Badge"></li>
<li><i><b>Improving low-resource languages in pre-trained multilingual language models</b></i>, Hangya et al., <img src="https://img.shields.io/badge/EMNLP-2022-green" alt="EMNLP Badge"></li>
<li><i><b>Hit-scir at mmnlu-22: Consistency regularization for multilingual spoken language understanding</b></i>, Zheng et al., <a href="https://arxiv.org/abs/2301.02010" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Crosslingual capabilities and knowledge barriers in multilingual large language models</b></i>, Chua et al., <a href="https://arxiv.org/abs/2406.16135" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoCAP: Towards automatic cross-lingual alignment planning for zero-shot chain-of-thought</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2406.13940" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Rule-based, neural and LLM back-translation: Comparative insights from a variant of Ladin</b></i>, Frontull et al., <a href="https://arxiv.org/abs/2407.08819" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>A survey of multilingual large language models</b></i>, Qin et al., <img src="https://img.shields.io/badge/Patterns-2025-green" alt="Patterns Badge"></li>
<li><i><b>A smack of all neighbouring languages: How multilingual is scholarly communication?</b></i>, Pradier et al., <a href="https://arxiv.org/abs/2504.21100" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System</b></i>, Wang et al., <a href="https://arxiv.org/abs/2505.15372" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>
<h2 id="related-materials">8. Related Materials</h2>
<img src="./assets/images/related_work.png" style="width: 580pt">
<ul>
<li><i><b>AI-powered platform for scientific discovery</b></i>, Trifonov et al., <img src="https://img.shields.io/badge/Other Source-.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Hypothesis generation with large language models</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2404.04326" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence and scientific discovery: A model of prioritized search</b></i>, Agrawal et al., <img src="https://img.shields.io/badge/Research Policy-2024-green" alt="Research Policy Badge"></li>
<li><i><b>A comprehensive survey of scientific large language models and their applications in scientific discovery</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2406.10833" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Artificial intelligence for literature reviews: Opportunities and challenges</b></i>, Bolanos et al., <img src="https://img.shields.io/badge/Artificial Intelligence Review-2024-green" alt="Artificial Intelligence Review Badge"></li>
<li><i><b>Creativity in AI: Progresses and Challenges</b></i>, Ismayilzada et al., <a href="https://arxiv.org/abs/2410.17218" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and Perceptions</b></i>, Liao et al., <a href="https://arxiv.org/abs/2411.05025" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards scientific discovery with generative ai: Progress, opportunities, and challenges</b></i>, Reddy et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
<li><i><b>LLM4SR: A Survey on Large Language Models for Scientific Research</b></i>, Luo et al., <a href="https://arxiv.org/abs/2501.04306" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Large language models for automated scholarly paper review: A survey</b></i>, Zhuang et al., <a href="https://arxiv.org/abs/2501.10326" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models</b></i>, Barman et al., <a href="https://arxiv.org/abs/2501.05382" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation</b></i>, Eger et al., <a href="https://arxiv.org/abs/2502.05151" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Unlocking the Potential of AI Researchers in Scientific Discovery: What Is Missing?</b></i>, Yu et al., <a href="https://arxiv.org/abs/2503.05822" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>A review of llm-assisted ideation</b></i>, Li et al., <a href="https://arxiv.org/abs/2503.00946" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards scientific intelligence: A survey of llm-based scientific agents</b></i>, Ren et al., <a href="https://arxiv.org/abs/2503.24047" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Agentichypothesis: A survey on hypothesis generation using llm systems</b></i>, Bazgir et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions</b></i>, Gridach et al., <a href="https://arxiv.org/abs/2503.08979" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>A Survey on Hypothesis Generation for Scientific Discovery in the Era of Large Language Models</b></i>, Alkan et al., <a href="https://arxiv.org/abs/2504.05496" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2505.16477" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scientific hypothesis generation and validation: Methods, datasets, and future directions</b></i>, Kulkarni et al., <a href="https://arxiv.org/abs/2505.04651" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.12039" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation</b></i>, Huang et al., <img src="https://img.shields.io/badge/Other Source-2025.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards</b></i>, Kim et al., <a href="https://arxiv.org/abs/2505.04966" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery</b></i>, Zheng et al., <a href="https://arxiv.org/abs/2505.13259" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AI Scientists Fail Without Strong Implementation Capability</b></i>, Zhu et al., <a href="https://arxiv.org/abs/2506.01372" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>
<h2 id="resources">9. Resources</h2>


<h3 id="ai-for-scientific-comprehension">9.1 AI for Scientific Comprehension</h3>
<h4 id="textual-scientific-comprehension">9.1.1 Textual Scientific Comprehension</h4>
<ul>
<li><i><b>Pubmedqa: A dataset for biomedical research question answering</b></i>, Jin et al., <a href="https://arxiv.org/abs/1909.06146" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering</b></i>, Pal et al., <img src="https://img.shields.io/badge/Other Source-2022.04-lightgrey" alt="Other Source Badge"></li>
<li><i><b>CoQUAD: a COVID-19 question answering dataset system, facilitating research, benchmarking, and practice</b></i>, Raza et al., <img src="https://img.shields.io/badge/BMC bioinformatics-2022-green" alt="BMC bioinformatics Badge"></li>
<li><i><b>Scienceqa: A novel resource for question answering on scholarly articles</b></i>, Saikh et al., <img src="https://img.shields.io/badge/Other Source-2022.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Clam: Selective clarification for ambiguous questions with generative language models</b></i>, Kuhn et al., <a href="https://arxiv.org/abs/2212.07769" target="_blank"><img src="https://img.shields.io/badge/arXiv-2022.12-red" alt="arXiv Badge"></a></li>
<li><i><b>BioASQ-QA: A manually curated corpus for Biomedical Question Answering</b></i>, Krithara et al., <img src="https://img.shields.io/badge/Scientific Data-2023-green" alt="Scientific Data Badge"></li>
<li><i><b>The sciqa scientific question answering benchmark for scholarly knowledge</b></i>, Auer et al., <img src="https://img.shields.io/badge/Scientific Reports-2023-green" alt="Scientific Reports Badge"></li>
<li><i><b>Theoremqa: A theorem-driven question answering dataset</b></i>, Chen et al., <a href="https://arxiv.org/abs/2305.12524" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scibench: Evaluating college-level scientific problem-solving abilities of large language models</b></i>, Wang et al., <a href="https://arxiv.org/abs/2307.10635" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.07-red" alt="arXiv Badge"></a></li>
<li><i><b>What if: Generating code to answer simulation questions in chemistry texts</b></i>, Peretz et al., <img src="https://img.shields.io/badge/Other Source-2023.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Enabling Language Models to Implicitly Learn Self-Improvement</b></i>, Wang et al., <a href="https://arxiv.org/abs/2310.00898" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Paperqa: Retrieval-augmented generative agent for scientific research</b></i>, L{\'a}la et al., <a href="https://arxiv.org/abs/2312.07559" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciglm: Training scientific language models with self-reflective instruction annotation and tuning</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2401.07950" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Generating Multiple Choice Questions from Scientific Literature via Large Language Models</b></i>, Luo et al., <img src="https://img.shields.io/badge/Other Source-2024.02-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Biomedlm: A 2.7 b parameter language model trained on biomedical text</b></i>, Bolton et al., <a href="https://arxiv.org/abs/2403.18421" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.03-red" alt="arXiv Badge"></a></li>
<li><i><b>SciQAG: A Framework for Auto-Generated Science Question Answering Dataset with Fine-grained Evaluation</b></i>, Wan et al., <a href="https://arxiv.org/abs/2405.09939" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>M <sup>3</sup> CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought</b></i>, Chen et al., <a href="https://arxiv.org/abs/2405.16473" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scifibench: Benchmarking large multimodal models for scientific figure interpretation</b></i>, Roberts et al., <a href="https://arxiv.org/abs/2405.08807" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Sciknoweval: Evaluating multi-level scientific knowledge of large language models</b></i>, Feng et al., <a href="https://arxiv.org/abs/2406.09098" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science</b></i>, Lin et al., <a href="https://arxiv.org/abs/2407.00466" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Scholarchemqa: Unveiling the power of language models in chemical research question answering</b></i>, Chen et al., <a href="https://arxiv.org/abs/2407.16931" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Mmsci: A dataset for graduate-level multi-discipline multimodal scientific understanding</b></i>, Li et al., <a href="https://arxiv.org/abs/2407.04903" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</b></i>, Pramanick et al., <a href="https://openreview.net/forum?id=h3lddsY5nf" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.07-blue" alt="PDF Badge"></a></li>
<li><i><b>Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models</b></i>, Li et al., <a href="https://aclanthology.org/2024.acl-long.775/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark</b></i>, Liang et al., <a href="https://aclanthology.org/2024.acl-short.11/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>Language agents achieve superhuman synthesis of scientific knowledge</b></i>, Skarlinski et al., <a href="https://arxiv.org/abs/2409.13740" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study</b></i>, Rostam et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Graphusion: a RAG framework for Knowledge Graph Construction with a global perspective</b></i>, Yang et al., <a href="https://arxiv.org/abs/2410.17600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models</b></i>, Li et al., <a href="https://aclanthology.org/2024.findings-emnlp.904/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers</b></i>, Singh et al., <a href="https://arxiv.org/abs/2411.05338" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.11-red" alt="arXiv Badge"></a></li>
<li><i><b>SciAgent: Tool-augmented Language Models for Scientific Reasoning</b></i>, Ma et al., <a href="https://aclanthology.org/2024.emnlp-main.880/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.11-blue" alt="PDF Badge"></a></li>
<li><i><b>SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature</b></i>, Wadden et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>PaSa: An LLM Agent for Comprehensive Academic Paper Search</b></i>, He et al., <a href="https://arxiv.org/abs/2501.10120" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.01-red" alt="arXiv Badge"></a></li>
<li><i><b>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2502.16660" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoPaperBench: An MLLM-Based Framework for Automatic Generation of Paper Understanding Evaluation Benchmarks</b></i>, Kim et al., <img src="https://img.shields.io/badge/Electronics-2025-green" alt="Electronics Badge"></li>
<li><i><b>FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights</b></i>, Yu et al., <a href="https://arxiv.org/abs/2505.04649" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models</b></i>, Yu et al., <a href="https://arxiv.org/abs/2505.15094" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models</b></i>, Xu et al., <a href="https://arxiv.org/abs/2505.17139" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scaling Physical Reasoning with the PHYSICS Dataset</b></i>, Zheng et al., <a href="https://arxiv.org/abs/2506.00022" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<h4 id="table-chart-scientific-comprehension">9.1.2 Table & Chart Scientific Comprehension</h4>
</ul>

<ul>
<li><i><b>ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning</b></i>, Masry et al., <a href="https://aclanthology.org/2022.findings-acl.177/" target="_blank"><img src="https://img.shields.io/badge/PDF-2022.05-blue" alt="PDF Badge"></a></li>
<li><i><b>Chartx & chartvlm: A versatile benchmark and foundation model for complicated chart reasoning</b></i>, Xia et al., <a href="https://arxiv.org/abs/2402.12185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study</b></i>, Sui et al., <a href="https://doi.org/10.1145/3616855.3635752" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.03-blue" alt="PDF Badge"></a></li>
<li><i><b>NovaChart: A Large-scale Dataset towards Chart Understanding and Generation of Multimodal Large Language Models</b></i>, Hu et al., <a href="https://openreview.net/forum?id=PTYL6011vp" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.10-blue" alt="PDF Badge"></a></li>
<li><i><b>CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs</b></i>, Wang et al., <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/cdf6f8e9fd9aeaf79b6024caec24f15b-Paper-Datasets_and_Benchmarks_Track.pdf" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.12-blue" alt="PDF Badge"></a></li>
<li><i><b>The Mighty ToRR: A Benchmark for Table Reasoning and Robustness</b></i>, Ashury-Tahan et al., <a href="https://arxiv.org/abs/2502.19412" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Tablebench: A comprehensive and complex benchmark for table question answering</b></i>, Wu et al., <img src="https://img.shields.io/badge/AAAI-2025-green" alt="AAAI Badge"></li>
</ul>



<h3 id="ai-for-academic-survey">9.2 AI for Academic Survey</h3>
</ul>

<ul>
<li><i><b>Ms2: Multi-document summarization of medical studies</b></i>, DeYoung et al., <a href="https://arxiv.org/abs/2104.06486" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Generating (factual?) narrative summaries of rcts: Experiments with neural multi-document summarization</b></i>, Wallace et al., <img src="https://img.shields.io/badge/Other Source-2021.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Overview of MSLR2022: A shared task on multi-document summarization for literature reviews</b></i>, Wang et al., <img src="https://img.shields.io/badge/Other Source-2022.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Generating a structured summary of numerous academic papers: Dataset and method</b></i>, Liu et al., <a href="https://arxiv.org/abs/2302.04580" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.02-red" alt="arXiv Badge"></a></li>
<li><i><b>SciReviewGen: a large-scale dataset for automatic literature review generation</b></i>, Kasanishi et al., <a href="https://arxiv.org/abs/2305.15186" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>SurveySum: A Dataset for Summarizing Multiple Scientific Articles into a Survey Section</b></i>, Fernandes et al., <img src="https://img.shields.io/badge/Other Source-2024.01-lightgrey" alt="Other Source Badge"></li>
<li><i><b>OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2402.15810" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>OARelatedWork: A Large-Scale Dataset of Related Work Sections with Full-texts from Open Access Sources</b></i>, Docekal et al., <a href="https://arxiv.org/abs/2405.01930" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Autosurvey: Large language models can automatically write surveys</b></i>, Wang et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>SurveyX: Academic Survey Automation via Large Language Models</b></i>, Liang et al., <a href="https://arxiv.org/abs/2502.14776" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</b></i>, Yan et al., <a href="https://arxiv.org/abs/2503.04629" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Browsecomp: A simple yet challenging benchmark for browsing agents</b></i>, Wei et al., <a href="https://arxiv.org/abs/2504.12516" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>LLM </sup>times</sup> MapReduce-V2: Entropy-Driven Convolutional Test-Time Scaling for Generating Long-Form Articles from Extremely Long Resources</b></i>, Wang et al., <a href="https://arxiv.org/abs/2504.05732" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>AcademicBrowse: Benchmarking Academic Browse Ability of LLMs</b></i>, Zhou et al., <a href="https://arxiv.org/abs/2506.13784" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="ai-for-scientific-discovery">9.3 AI for Scientific Discovery</h3>
</ul>

<b>Idea Mining</b>
<ul>
<li><i><b>OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2402.15810" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Can Large Language Models Unlock Novel Scientific Research Ideas?</b></i>, Kumar et al., <a href="https://arxiv.org/abs/2409.06185" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>LiveIdeaBench: Evaluating LLMs' Scientific Creativity and Idea Generation with Minimal Context</b></i>, Ruan et al., <a href="https://arxiv.org/abs/2412.17596" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses</b></i>, Yang et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Learning to Generate Research Idea with Dynamic Control</b></i>, Li et al., <a href="https://arxiv.org/abs/2412.14626" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations</b></i>, Chen et al., <a href="https://arxiv.org/abs/2503.18865" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition</b></i>, Liu et al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Ai idea bench 2025: Ai research idea generation benchmark</b></i>, Qiu et al., <a href="https://arxiv.org/abs/2504.14191" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Sparks of science: Hypothesis generation using structured paper data</b></i>, O'Neill et al., <a href="https://arxiv.org/abs/2504.12976" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Spark: A System for Scientifically Creative Idea Generation</b></i>, Sanyal et al., <a href="https://arxiv.org/abs/2504.20090" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.21396" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature</b></i>, Sternlicht et al., <a href="https://arxiv.org/abs/2505.20779" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Novelty & Significant Assessment</b>
<ul>
<li><i><b>Blade: Benchmarking language model agents for data-driven science</b></i>, Gu et al., <a href="https://arxiv.org/abs/2408.09667" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Empowering AI as Autonomous Researchers: Evaluating LLMs in Generating Novel Research Ideas through Automated Metrics</b></i>, Dasgupta et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>LLMs Tackle Meta-Analysis: Automating Scientific Hypothesis Generation with Statistical Rigor</b></i>, Lin et al., <img src="https://img.shields.io/badge/Other Source-2024.12-lightgrey" alt="Other Source Badge"></li>
<li><i><b>A Hierarchical Framework for Measuring Scientific Paper Innovation via Large Language Models</b></i>, Tan et al., <a href="https://arxiv.org/abs/2504.14620" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Hypobench: Towards systematic and principled benchmarking for hypothesis generation</b></i>, Liu et al., <a href="https://arxiv.org/abs/2504.11524" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications</b></i>, Lin et al., <a href="https://aclanthology.org/2025.aisd-main.5/" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.05-blue" alt="PDF Badge"></a></li>
<li><i><b>Harnessing Large Language Models for Scientific Novelty Detection</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.24615" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Theory Analysis</b>
<ul>
<li><i><b>Minif2f: a cross-system benchmark for formal olympiad-level mathematics</b></i>, Zheng et al., <a href="https://arxiv.org/abs/2109.00110" target="_blank"><img src="https://img.shields.io/badge/arXiv-2021.09-red" alt="arXiv Badge"></a></li>
<li><i><b>FactKG: Fact verification via reasoning on knowledge graphs</b></i>, Kim et al., <a href="https://arxiv.org/abs/2305.06590" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Investigating zero-and few-shot generalization in fact verification</b></i>, Pan et al., <a href="https://arxiv.org/abs/2309.09444" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Fimo: A challenge formal dataset for automated theorem proving</b></i>, Liu et al., <a href="https://arxiv.org/abs/2309.04295" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Can Large Language Models Detect Misinformation in Scientific News Reporting?</b></i>, Cao et al., <a href="https://arxiv.org/abs/2402.14268" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Mustard: Mastering uniform synthesis of theorem and proof data</b></i>, Huang et al., <a href="https://arxiv.org/abs/2402.08957" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>MAGIC: Multi-Argument Generation with Self-Refinement for Domain Generalization in Automatic Fact-Checking</b></i>, Kao et al., <img src="https://img.shields.io/badge/COLING-2024-green" alt="COLING Badge"></li>
<li><i><b>Zero-shot scientific claim verification using LLMs and citation text</b></i>, Alvarez et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Grounding fallacies misrepresenting scientific publications in evidence</b></i>, Glockner et al., <a href="https://arxiv.org/abs/2408.12812" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Augmenting the Veracity and Explanations of Complex Fact Checking via Iterative Self-Revision with LLMs</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2410.15135" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts</b></i>, Braun et al., <a href="https://arxiv.org/abs/2412.10510" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding</b></i>, Ku et al., <a href="https://arxiv.org/abs/2502.19400" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research</b></i>, Wang et al., <a href="https://arxiv.org/abs/2505.16100" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Experiment Design</b>
<ul>
<li><i><b>Benchmarking compound activity prediction for real-world drug discovery applications</b></i>, Tian et al., <img src="https://img.shields.io/badge/Communications Chemistry-2024-green" alt="Communications Chemistry Badge"></li>
<li><i><b>A bioactivity foundation model using pairwise meta-learning</b></i>, Feng et al., <img src="https://img.shields.io/badge/Nature-2024-green" alt="Nature Badge"></li>
<li><i><b>BioProBench: Comprehensive Dataset and Benchmark in Biological Protocol Understanding and Reasoning</b></i>, Liu et al., <a href="https://arxiv.org/abs/2505.07889" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2506.04078" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>Experiment Conduction</b>
<ul>
<li><i><b>Mlagentbench: Evaluating language agents on machine learning experimentation</b></i>, Huang et al., <a href="https://arxiv.org/abs/2310.03302" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Infiagent-dabench: Evaluating agents on data analysis tasks</b></i>, Hu et al., <a href="https://arxiv.org/abs/2401.05507" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?</b></i>, Jing et al., <a href="https://arxiv.org/abs/2409.07703" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Mle-bench: Evaluating machine learning agents on machine learning engineering</b></i>, Chan et al., <a href="https://arxiv.org/abs/2410.07095" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Mlgym: A new framework and benchmark for advancing ai research agents</b></i>, Nathani et al., <a href="https://arxiv.org/abs/2502.14499" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2504.09702" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Scireplicate-bench: Benchmarking llms in agent-driven algorithmic reproduction from research papers</b></i>, Xiang et al., <a href="https://arxiv.org/abs/2504.00255" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Can AI Agents Design and Implement Drug Discovery Pipelines?</b></i>, Smbatyan et al., <a href="https://arxiv.org/abs/2504.19912" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>EXP-Bench: Can AI Conduct AI Research Experiments?</b></i>, Kon et al., <a href="https://arxiv.org/abs/2505.24785" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Scienceboard: Evaluating multimodal autonomous agents in realistic scientific workflows</b></i>, Sun et al., <a href="https://arxiv.org/abs/2505.19897" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage</b></i>, Zhao et al., <a href="https://arxiv.org/abs/2505.20662" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.19955" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Autobio: A simulation and benchmark for robotic automation in digital biology laboratory</b></i>, Lan et al., <a href="https://arxiv.org/abs/2505.14030" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code</b></i>, Hua et al., <a href="https://arxiv.org/abs/2506.02314" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.06-red" alt="arXiv Badge"></a></li>
</ul>

<b>Experimental Analysis</b>
<ul>
<li><i><b>Microvqa: A multimodal reasoning benchmark for microscopy-based scientific research</b></i>, Burgess et al., <img src="https://img.shields.io/badge/Other Source-2025.03-lightgrey" alt="Other Source Badge"></li>
</ul>

<b>Full Automatic Discovery</b>
<ul>
<li><i><b>Ds-agent: Automated data science by empowering large language models with case-based reasoning</b></i>, Guo et al., <a href="https://arxiv.org/abs/2402.17453" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>Discoverybench: Towards data-driven discovery with large language models</b></i>, Majumder et al., <a href="https://arxiv.org/abs/2407.01725" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>Blade: Benchmarking language model agents for data-driven science</b></i>, Gu et al., <a href="https://arxiv.org/abs/2408.09667" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Scienceagentbench: Toward rigorous assessment of language agents for data-driven scientific discovery</b></i>, Chen et al., <a href="https://arxiv.org/abs/2410.05080" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>DISCOVERYWORLD: A virtual environment for developing and evaluating automated scientific discovery agents</b></i>, Jansen et al., <img src="https://img.shields.io/badge/NeurIPS-2024-green" alt="NeurIPS Badge"></li>
<li><i><b>Curie: Toward rigorous and automated scientific experimentation with ai agents</b></i>, Kon et al., <a href="https://arxiv.org/abs/2502.16069" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>A vision for auto research with llm agents</b></i>, Liu et al., <a href="https://arxiv.org/abs/2504.18765" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Can AI Agents Design and Implement Drug Discovery Pipelines?</b></i>, Smbatyan et al., <a href="https://arxiv.org/abs/2504.19912" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Llm-srbench: A new benchmark for scientific equation discovery with large language models</b></i>, Shojaee et al., <a href="https://arxiv.org/abs/2504.10415" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Towards llm agents for earth observation</b></i>, Kao et al., <a href="https://arxiv.org/abs/2504.12110" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>Benchmarking AI scientists in omics data-driven biological research</b></i>, Luo et al., <a href="https://arxiv.org/abs/2505.08341" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<ul>
<li><i><b>ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition</b></i>, Liu et al., <a href="https://arxiv.org/abs/2503.21248" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
</ul>



<h3 id="ai-for-academic-writing">9.4 AI for Academic Writing</h3>
<h4 id="semi-automatic-academic-writing">9.4.3 Semi-Automatic Academic Writing</h4>
</ul>

<b>Assistance During Manuscript Preparation.</b>
<ul>
<li><i><b>LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts</b></i>, Hashemi et al., <a href="https://aclanthology.org/2024.acl-long.745/" target="_blank"><img src="https://img.shields.io/badge/PDF-2024.08-blue" alt="PDF Badge"></a></li>
<li><i><b>MoDeST: A dataset for Multi Domain Scientific Title Generation</b></i>, Bölücü et al., <a href="https://www.sciencedirect.com/science/article/pii/S0950705125006033" target="_blank"><img src="https://img.shields.io/badge/PDF-2025.06-blue" alt="PDF Badge"></a></li>
</ul>

<b>Assistance During Manuscript Writing</b>
<ul>
<li><i><b>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding</b></i>, Wright et al., <img src="https://img.shields.io/badge/ACL Findings-2021-green" alt="ACL Findings Badge"></li>
<li><i><b>Figgen: Text to scientific figure generation</b></i>, Rodriguez et al., <a href="https://arxiv.org/abs/2306.00800" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Scicapenter: Supporting caption composition for scientific figures with machine-generated captions and ratings</b></i>, Hsu et al., <img src="https://img.shields.io/badge/Other Source-2024.05-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Figuring out Figures: Using Textual References to Caption Scientific Figures</b></i>, Cao et al., <a href="https://arxiv.org/abs/2407.11008" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.07-red" alt="arXiv Badge"></a></li>
<li><i><b>CiteBART: Learning to Generate Citations for Local Citation Recommendation</b></i>, {\c{C}}elik et al., <a href="https://arxiv.org/abs/2412.17534" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>TikZero: Zero-Shot Text-Guided Graphics Program Synthesis</b></i>, Belouadi et al., <a href="https://arxiv.org/abs/2503.11509" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>Futuregen: Llm-rag approach to generate the future work of scientific article</b></i>, Azher et al., <a href="https://arxiv.org/abs/2503.16561" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.03-red" alt="arXiv Badge"></a></li>
<li><i><b>ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations</b></i>, Wang et al., <a href="https://arxiv.org/abs/2504.00824" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision</b></i>, Chen et al., <a href="https://arxiv.org/abs/2505.11336" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
</ul>

<b>Assistance After Manuscript Completion.</b>
<ul>
<li><i><b>WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling language and discourse</b></i>, Faruqui et al., <a href="https://arxiv.org/abs/1808.09422" target="_blank"><img src="https://img.shields.io/badge/arXiv-2018.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Learning to split and rephrase from Wikipedia edit history</b></i>, Botha et al., <a href="https://arxiv.org/abs/1808.09468" target="_blank"><img src="https://img.shields.io/badge/arXiv-2018.08-red" alt="arXiv Badge"></a></li>
<li><i><b>Diamonds in the rough: Generating fluent sentences from early-stage drafts for academic writing assistance</b></i>, Ito et al., <a href="https://arxiv.org/abs/1910.09180" target="_blank"><img src="https://img.shields.io/badge/arXiv-2019.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Neural Automated Writing Evaluation with Corrective Feedback</b></i>, Wang et al., <a href="https://arxiv.org/abs/2402.17613" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.02-red" alt="arXiv Badge"></a></li>
<li><i><b>AAAR-1.0: Assessing AI's Potential to Assist Research</b></i>, Lou et al., <a href="https://arxiv.org/abs/2410.22394" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers</b></i>, Pang et al., <a href="https://arxiv.org/abs/2505.21497" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>The usage of a transformer based and artificial intelligence driven multidimensional feedback system in english writing instruction</b></i>, Zheng et al., <img src="https://img.shields.io/badge/Scientific Reports-2025-green" alt="Scientific Reports Badge"></li>
</ul>



<h3 id="ai-for-academic-peer-reviewing">9.5 AI for Academic Peer Reviewing</h3>
<h4 id="application-of-ai-for-research">9.5.4 Application of AI for Research</h4>
</ul>

<ul>
<li><i><b>Comprehensive inventory of methane emissions from the U.S. oil and gas industry</b></i>, Chen et al., <img src="https://img.shields.io/badge/Science-2022-green" alt="Science Badge"></li>
<li><i><b>DGPCD: a high-precision point cloud dataset of Dougong in ancient Chinese architecture</b></i>, Wang et al., <img src="https://img.shields.io/badge/Scientific Data-2023-green" alt="Scientific Data Badge"></li>
</ul>

</ul>

<ul>
<li><i><b>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications</b></i>, Kang et al., <img src="https://img.shields.io/badge/NAACL-2018-green" alt="NAACL Badge"></li>
<li><i><b>Citetracked: A longitudinal dataset of peer reviews and citations</b></i>, Plank et al., <img src="https://img.shields.io/badge/Other Source-2019.07-lightgrey" alt="Other Source Badge"></li>
<li><i><b>COMPARE: a taxonomy and dataset of comparison discussions in peer reviews</b></i>, Singh et al., <img src="https://img.shields.io/badge/Other Source-2021.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>Peer review analyze: A novel benchmark resource for computational analysis of peer reviews</b></i>, Ghosal et al., <img src="https://img.shields.io/badge/Plos one-2022-green" alt="Plos one Badge"></li>
<li><i><b>Reviewergpt? an exploratory study on using large language models for paper reviewing</b></i>, Liu et al., <a href="https://arxiv.org/abs/2306.00622" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.06-red" alt="arXiv Badge"></a></li>
<li><i><b>NLPeer: A Unified Resource for the Computational Study of Peer Review</b></i>, Dycke et al., <a href="https://aclanthology.org/2023.acl-long.277/" target="_blank"><img src="https://img.shields.io/badge/PDF-2023.07-blue" alt="PDF Badge"></a></li>
<li><i><b>Moprd: A multidisciplinary open peer review dataset</b></i>, Lin et al., <img src="https://img.shields.io/badge/Neural Computing and Applications-2023-green" alt="Neural Computing and Applications Badge"></li>
<li><i><b>The Open Review-Based (ORB) dataset: Towards Automatic Assessment of Scientific Papers and Experiment Proposals in High-Energy Physics</b></i>, Szumega et al., <a href="https://arxiv.org/abs/2312.04576" target="_blank"><img src="https://img.shields.io/badge/arXiv-2023.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Pre: A peer review based large language model evaluator</b></i>, Chu et al., <a href="https://arxiv.org/abs/2401.15641" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.01-red" alt="arXiv Badge"></a></li>
<li><i><b>Is LLM a reliable reviewer? A comprehensive evaluation of LLM on automatic paper reviewing tasks</b></i>, Zhou et al., <img src="https://img.shields.io/badge/COLING-2024-green" alt="COLING Badge"></li>
<li><i><b>PolitePEER: does peer review hurt? A dataset to gauge politeness intensity in the peer reviews</b></i>, Bharti et al., <img src="https://img.shields.io/badge/Language Resources and Evaluation-2024-green" alt="Language Resources and Evaluation Badge"></li>
<li><i><b>RelevAI-Reviewer: A Benchmark on AI Reviewers for Survey Paper Relevance</b></i>, Couto et al., <a href="https://arxiv.org/abs/2406.10294" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Peer review as a multi-turn and long-context dialogue with role-based interactions</b></i>, Tan et al., <a href="https://arxiv.org/abs/2406.05688" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>MASSW: A new dataset and benchmark tasks for ai-assisted scientific workflows</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2406.06357" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.06-red" alt="arXiv Badge"></a></li>
<li><i><b>Scientific opinion summarization: Paper meta-review generation dataset, methods, and evaluation</b></i>, Zeng et al., <img src="https://img.shields.io/badge/IJCAI-2024-green" alt="IJCAI Badge"></li>
<li><i><b>Can large language models provide useful feedback on research papers? A large-scale empirical analysis</b></i>, Liang et al., <img src="https://img.shields.io/badge/NEJM AI-2024-green" alt="NEJM AI Badge"></li>
<li><i><b>An Analysis of Tasks and Datasets in Peer Reviewing</b></i>, Staudinger et al., <img src="https://img.shields.io/badge/Other Source-2024.08-lightgrey" alt="Other Source Badge"></li>
<li><i><b>PeerArg: Argumentative Peer Review with LLMs</b></i>, Sukpanichnant et al., <a href="https://arxiv.org/abs/2409.16813" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.09-red" alt="arXiv Badge"></a></li>
<li><i><b>Enhancing peer review efficiency: A mixed-methods analysis of artificial intelligence-assisted reviewer selection across academic disciplines</b></i>, Farber et al., <img src="https://img.shields.io/badge/Learned Publishing-2024-green" alt="Learned Publishing Badge"></li>
<li><i><b>Automatic Large Language Model Evaluation via Peer Review</b></i>, Chu et al., <img src="https://img.shields.io/badge/Other Source-2024.10-lightgrey" alt="Other Source Badge"></li>
<li><i><b>AAAR-1.0: Assessing AI's Potential to Assist Research</b></i>, Lou et al., <a href="https://arxiv.org/abs/2410.22394" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>Is your paper being reviewed by an llm? investigating ai text detectability in peer review</b></i>, Yu et al., <a href="https://arxiv.org/abs/2410.03019" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.10-red" alt="arXiv Badge"></a></li>
<li><i><b>WithdrarXiv: A Large-Scale Dataset for Retraction Study</b></i>, Rao et al., <a href="https://arxiv.org/abs/2412.03775" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews</b></i>, Idahl et al., <a href="https://arxiv.org/abs/2412.11948" target="_blank"><img src="https://img.shields.io/badge/arXiv-2024.12-red" alt="arXiv Badge"></a></li>
<li><i><b>Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM Reviews</b></i>, Shin et al., <a href="https://arxiv.org/abs/2502.17086" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>PeerQA: A Scientific Question Answering Dataset from Peer Reviews</b></i>, Baumg{\"a}rtner et al., <img src="https://img.shields.io/badge/ACL-2025-green" alt="ACL Badge"></li>
<li><i><b>Revieweval: An evaluation framework for ai-generated reviews</b></i>, Kirtani et al., <a href="https://arxiv.org/abs/2502.11736" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.02-red" alt="arXiv Badge"></a></li>
<li><i><b>LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews</b></i>, Purkayastha et al., <a href="https://arxiv.org/abs/2504.11042" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.04-red" alt="arXiv Badge"></a></li>
<li><i><b>When AI co-scientists fail: SPOT-a benchmark for automated verification of scientific research</b></i>, Son et al., <a href="https://arxiv.org/abs/2505.11855" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>Re <sup>2</sup>: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions</b></i>, Zhang et al., <a href="https://arxiv.org/abs/2505.07920" target="_blank"><img src="https://img.shields.io/badge/arXiv-2025.05-red" alt="arXiv Badge"></a></li>
<li><i><b>PaperEval: A universal, quantitative, and explainable paper evaluation method powered by a multi-agent system</b></i>, Huang et al., <img src="https://img.shields.io/badge/Information Processing & Management-2025-green" alt="Information Processing & Management Badge"></li>
</ul>
